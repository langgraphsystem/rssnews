#!/usr/bin/env python3
"""Check embedding history - which model was used when"""

import os
import sys
import json
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from dotenv import load_dotenv
load_dotenv()

from pg_client_new import PgClient


def check_history():
    client = PgClient()

    print("=== –ò—Å—Ç–æ—Ä–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ ===\n")

    with client._cursor() as cur:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∞–º—ã–µ —Å—Ç–∞—Ä—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
        print("üìÖ –°–ê–ú–´–ï –°–¢–ê–†–´–ï —ç–º–±–µ–¥–¥–∏–Ω–≥–∏:")
        cur.execute('''
            SELECT id, embedding, created_at
            FROM article_chunks
            WHERE embedding IS NOT NULL
            ORDER BY id ASC
            LIMIT 3
        ''')

        for row in cur.fetchall():
            chunk_id, emb, created = row
            emb_list = json.loads(emb) if isinstance(emb, str) else emb
            dim = len(emb_list)

            if dim == 768:
                model = "embeddinggemma (Ollama - –õ–û–ö–ê–õ–¨–ù–ê–Ø)"
            elif dim == 1536:
                model = "text-embedding-ada-002 (OpenAI)"
            elif dim == 3072:
                model = "text-embedding-3-large (OpenAI)"
            else:
                model = f"Unknown ({dim} dim)"

            print(f"  ID {chunk_id}: {dim} dim ‚Üí {model}")
            print(f"    –°–æ–∑–¥–∞–Ω: {created}")

        print()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∞–º—ã–µ –Ω–æ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
        print("üÜï –°–ê–ú–´–ï –ù–û–í–´–ï —ç–º–±–µ–¥–¥–∏–Ω–≥–∏:")
        cur.execute('''
            SELECT id, embedding, created_at
            FROM article_chunks
            WHERE embedding IS NOT NULL
            ORDER BY id DESC
            LIMIT 3
        ''')

        for row in cur.fetchall():
            chunk_id, emb, created = row
            emb_list = json.loads(emb) if isinstance(emb, str) else emb
            dim = len(emb_list)

            if dim == 768:
                model = "embeddinggemma (Ollama - –õ–û–ö–ê–õ–¨–ù–ê–Ø)"
            elif dim == 1536:
                model = "text-embedding-ada-002 (OpenAI)"
            elif dim == 3072:
                model = "text-embedding-3-large (OpenAI)"
            else:
                model = f"Unknown ({dim} dim)"

            print(f"  ID {chunk_id}: {dim} dim ‚Üí {model}")
            print(f"    –°–æ–∑–¥–∞–Ω: {created}")

        print()
        print("="*60)
        print()

        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –ú–û–î–ï–õ–Ø–ú:")

        # –°—á–∏—Ç–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –≤—Ä—É—á–Ω—É—é –∏–∑ –ø–µ—Ä–≤—ã—Ö 1000
        cur.execute('''
            SELECT embedding
            FROM article_chunks
            WHERE embedding IS NOT NULL
            LIMIT 1000
        ''')

        dim_counts = {768: 0, 1536: 0, 3072: 0, 'other': 0}

        for row in cur.fetchall():
            emb = json.loads(row[0]) if isinstance(row[0], str) else row[0]
            dim = len(emb)
            if dim in dim_counts:
                dim_counts[dim] += 1
            else:
                dim_counts['other'] += 1

        total_sample = sum(dim_counts.values())

        if dim_counts[768] > 0:
            print(f"  768-dim (embeddinggemma LOCAL): {dim_counts[768]}/{total_sample} ({100*dim_counts[768]//total_sample}%)")
        if dim_counts[1536] > 0:
            print(f"  1536-dim (ada-002 OpenAI): {dim_counts[1536]}/{total_sample} ({100*dim_counts[1536]//total_sample}%)")
        if dim_counts[3072] > 0:
            print(f"  3072-dim (3-large OpenAI): {dim_counts[3072]}/{total_sample} ({100*dim_counts[3072]//total_sample}%)")
        if dim_counts['other'] > 0:
            print(f"  Other: {dim_counts['other']}/{total_sample}")

        print(f"\n  (–í—ã–±–æ—Ä–∫–∞ –∏–∑ {total_sample} —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤)")

        print()
        print("="*60)
        print()

        # –í–´–í–û–î
        print("üí° –í–´–í–û–î–´:")
        print()

        if dim_counts[3072] > dim_counts[768]:
            print("  ‚úÖ –°–ï–ô–ß–ê–° –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è: OpenAI text-embedding-3-large (3072-dim)")
            print("  üí∏ –°—Ç–æ–∏–º–æ—Å—Ç—å: ~$0.00013 –∑–∞ 1K —Ç–æ–∫–µ–Ω–æ–≤")
            print()
            if dim_counts[768] > 0:
                print("  üìú –†–ê–ù–¨–®–ï –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–æ—Å—å: embeddinggemma (768-dim) - –ª–æ–∫–∞–ª—å–Ω–∞—è")
                print("  üí∞ –ë—ã–ª–æ –±–µ—Å–ø–ª–∞—Ç–Ω–æ, –Ω–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ")
                print()
                print("  üîÑ –ü—Ä–æ–∏–∑–æ—à—ë–ª –ø–µ—Ä–µ—Ö–æ–¥ —Å –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ OpenAI API")
        elif dim_counts[768] > dim_counts[3072]:
            print("  ‚úÖ –û–°–ù–û–í–ù–ê–Ø –ß–ê–°–¢–¨: embeddinggemma (768-dim) - –õ–û–ö–ê–õ–¨–ù–ê–Ø")
            print("  üí∞ –ë–µ—Å–ø–ª–∞—Ç–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç —á–µ—Ä–µ–∑ Ollama")
            print()
            if dim_counts[3072] > 0:
                print("  üÜï –ù–ï–î–ê–í–ù–û –¥–æ–±–∞–≤–ª–µ–Ω–æ: OpenAI text-embedding-3-large (3072-dim)")
                print("  üí∏ –ü–ª–∞—Ç–Ω–æ: ~$0.00013 –∑–∞ 1K —Ç–æ–∫–µ–Ω–æ–≤")

        print()
        print("="*60)
        print()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∫–∞—è –º–æ–¥–µ–ª—å —Å–µ–π—á–∞—Å –≤ –∫–æ–Ω—Ñ–∏–≥–µ
        print("‚öôÔ∏è  –¢–ï–ö–£–©–ê–Ø –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø:")
        embedding_model = os.getenv('EMBEDDING_MODEL', 'embeddinggemma')
        ollama_url = os.getenv('OLLAMA_BASE_URL', 'http://localhost:11434')
        openai_key = os.getenv('OPENAI_API_KEY')

        print(f"  EMBEDDING_MODEL: {embedding_model}")
        print(f"  OLLAMA_BASE_URL: {ollama_url}")
        print(f"  OPENAI_API_KEY: {'‚úÖ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω' if openai_key else '‚ùå –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω'}")
        print()

        if dim_counts[3072] > 0 and embedding_model == 'embeddinggemma':
            print("  ‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –í –ë–î –µ—Å—Ç—å 3072-dim —ç–º–±–µ–¥–¥–∏–Ω–≥–∏, –Ω–æ –∫–æ–Ω—Ñ–∏–≥ —É–∫–∞–∑—ã–≤–∞–µ—Ç embeddinggemma!")
            print("  –í–æ–∑–º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥—Ä—É–≥–æ–π –∫–æ–¥ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.")


if __name__ == '__main__':
    check_history()
