#!/usr/bin/env python3
"""
ü§ñ Comprehensive Testing Suite for GPT-5 Data Analysis Commands
–ü–æ–ª–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –∫–æ–º–∞–Ω–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö

–ö–æ–º–∞–Ω–¥—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:
‚Ä¢ /analyze [query] [timeframe] - Deep data analysis
‚Ä¢ /summarize [topic] [length] - AI-powered summaries
‚Ä¢ /aggregate [metric] [groupby] - Data aggregation
‚Ä¢ /filter [criteria] [value] - Smart filtering
‚Ä¢ /insights [topic] - Business insights generation
‚Ä¢ /sentiment [query] - Sentiment analysis
‚Ä¢ /topics [scope] - Topic modeling & trends
"""

import asyncio
import json
import logging
import os
import sys
import time
from datetime import datetime
from typing import Dict, Any, List

# Setup comprehensive logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('data_analysis_comprehensive_test.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# Load environment
try:
    from dotenv import load_dotenv
    load_dotenv()
    logger.info("‚úÖ Environment variables loaded")
except ImportError:
    logger.warning("‚ö†Ô∏è dotenv not available")

class DataAnalysisTestSuite:
    """Comprehensive test suite for all data analysis commands"""

    def __init__(self):
        self.test_results = {}
        self.total_start_time = None
        self.test_data = {
            'tech_articles': self._get_tech_test_data(),
            'market_articles': self._get_market_test_data(),
            'general_articles': self._get_general_test_data()
        }

    def _get_tech_test_data(self) -> List[Dict[str, Any]]:
        """Tech-focused test data"""
        return [
            {
                'title': '–†–µ–≤–æ–ª—é—Ü–∏—è –≤ –ò–ò: GPT-5 –º–µ–Ω—è–µ—Ç –∏–Ω–¥—É—Å—Ç—Ä–∏—é —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π',
                'content': '–ù–æ–≤–∞—è –º–æ–¥–µ–ª—å GPT-5 –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –±–µ—Å–ø—Ä–µ—Ü–µ–¥–µ–Ω—Ç–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≤ –æ–±–ª–∞—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –±–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å–æ–≤. –≠–∫—Å–ø–µ—Ä—Ç—ã –æ—Ç–º–µ—á–∞—é—Ç 40% —É–ª—É—á—à–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ –≤–µ—Ä—Å–∏—è–º–∏...',
                'source': 'TechNews',
                'source_domain': 'technews.com',
                'published_at': '2025-09-25T10:00:00',
                'score': 0.95,
                'tags': ['AI', 'GPT-5', 'technology', 'automation']
            },
            {
                'title': '–ö–≤–∞–Ω—Ç–æ–≤—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è: –ø—Ä–æ—Ä—ã–≤ –≤ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö',
                'content': '–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –¥–æ—Å—Ç–∏–≥–ª–∏ –Ω–æ–≤–æ–≥–æ —Ä–µ–∫–æ—Ä–¥–∞ –≤ –∫–≤–∞–Ω—Ç–æ–≤—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏—è—Ö, —á—Ç–æ –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç –Ω–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö. –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –≤ —Ç—ã—Å—è—á–∏ —Ä–∞–∑...',
                'source': 'QuantumTech',
                'source_domain': 'quantumtech.com',
                'published_at': '2025-09-25T09:30:00',
                'score': 0.92,
                'tags': ['quantum', 'computing', 'data', 'ML']
            },
            {
                'title': '–ë–ª–æ–∫—á–µ–π–Ω —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –≤ 2025: –Ω–æ–≤—ã–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è',
                'content': 'Blockchain –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —ç–≤–æ–ª—é—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞—Ç—å, –Ω–∞—Ö–æ–¥—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤ —Å–∏—Å—Ç–µ–º–∞—Ö –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö. –î–µ—Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–º–∏ –∏ –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏...',
                'source': 'BlockchainDaily',
                'source_domain': 'blockchain.daily',
                'published_at': '2025-09-25T08:45:00',
                'score': 0.88,
                'tags': ['blockchain', 'decentralization', 'analytics']
            }
        ]

    def _get_market_test_data(self) -> List[Dict[str, Any]]:
        """Market-focused test data"""
        return [
            {
                'title': '–†—ã–Ω–æ–∫ –ò–ò –¥–æ—Å—Ç–∏–≥–Ω–µ—Ç $500 –º–ª—Ä–¥ –∫ 2026 –≥–æ–¥—É',
                'content': '–ê–Ω–∞–ª–∏—Ç–∏–∫–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É—é—Ç –≤–∑—Ä—ã–≤–Ω–æ–π —Ä–æ—Å—Ç —Ä—ã–Ω–∫–∞ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞. –û—Å–Ω–æ–≤–Ω—ã–º–∏ –¥—Ä–∞–π–≤–µ—Ä–∞–º–∏ —Å—Ç–∞–Ω—É—Ç –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ –≤–Ω–µ–¥—Ä–µ–Ω–∏—è –∏ —Ä–∞–∑–≤–∏—Ç–∏–µ –∞–≤—Ç–æ–Ω–æ–º–Ω—ã—Ö —Å–∏—Å—Ç–µ–º. –ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏ —É–≤–µ–ª–∏—á–∏–ª–∏—Å—å –Ω–∞ 65% –∑–∞ –≥–æ–¥...',
                'source': 'MarketWatch',
                'source_domain': 'marketwatch.com',
                'published_at': '2025-09-25T11:00:00',
                'score': 0.94,
                'tags': ['market', 'AI', 'investment', 'growth']
            },
            {
                'title': '–ö—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω—ã–π —Ä—ã–Ω–æ–∫: –∞–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ Q3 2025',
                'content': '–¢—Ä–µ—Ç–∏–π –∫–≤–∞—Ä—Ç–∞–ª 2025 –≥–æ–¥–∞ –ø–æ–∫–∞–∑–∞–ª —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—é –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω–æ–≥–æ —Ä—ã–Ω–∫–∞. Bitcoin –∏ Ethereum –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç —É—Å—Ç–æ–π—á–∏–≤—ã–π —Ä–æ—Å—Ç, –≤ —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ –∞–ª—å—Ç–∫–æ–∏–Ω—ã –ø–µ—Ä–µ–∂–∏–≤–∞—é—Ç –ø–µ—Ä–∏–æ–¥ –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏...',
                'source': 'CryptoInsider',
                'source_domain': 'cryptoinsider.com',
                'published_at': '2025-09-25T10:30:00',
                'score': 0.89,
                'tags': ['crypto', 'market', 'trends', 'bitcoin']
            },
            {
                'title': '–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∞–∫—Ü–∏–∏: –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã —Ä–æ—Å—Ç–∞',
                'content': '–ê–∫—Ü–∏–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∫–æ–º–ø–∞–Ω–∏–π –ø—Ä–æ–¥–æ–ª–∂–∞—é—Ç –ø—Ä–∏–≤–ª–µ–∫–∞—Ç—å –∏–Ω–≤–µ—Å—Ç–æ—Ä–æ–≤. –û—Å–æ–±–µ–Ω–Ω–æ –≤—ã–¥–µ–ª—è—é—Ç—Å—è –∫–æ–º–ø–∞–Ω–∏–∏, —Ä–∞–±–æ—Ç–∞—é—â–∏–µ —Å –ò–ò –∏ –∫–≤–∞–Ω—Ç–æ–≤—ã–º–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è–º–∏. –ê–Ω–∞–ª–∏—Ç–∏–∫–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é—Ç –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –ø–æ—Ä—Ç—Ñ–µ–ª—è...',
                'source': 'InvestorDaily',
                'source_domain': 'investor.daily',
                'published_at': '2025-09-25T09:15:00',
                'score': 0.91,
                'tags': ['stocks', 'tech', 'investment', 'growth']
            }
        ]

    def _get_general_test_data(self) -> List[Dict[str, Any]]:
        """General news test data"""
        return [
            {
                'title': '–¶–∏—Ñ—Ä–æ–≤–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –º–µ–Ω—è–µ—Ç –±–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å—ã',
                'content': '–ö–æ–º–ø–∞–Ω–∏–∏ –≤—Å–µ—Ö –æ—Ç—Ä–∞—Å–ª–µ–π –∞–∫—Ç–∏–≤–Ω–æ –≤–Ω–µ–¥—Ä—è—é—Ç —Ü–∏—Ñ—Ä–æ–≤—ã–µ —Ä–µ—à–µ–Ω–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤. –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –∫–ª—é—á–µ–≤—ã–º–∏ —Ñ–∞–∫—Ç–æ—Ä–∞–º–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏...',
                'source': 'BusinessNews',
                'source_domain': 'business.news',
                'published_at': '2025-09-25T12:00:00',
                'score': 0.87,
                'tags': ['digital', 'transformation', 'business', 'automation']
            },
            {
                'title': '–≠–∫–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –Ω–∞–±–∏—Ä–∞—é—Ç –æ–±–æ—Ä–æ—Ç—ã',
                'content': 'Green Tech —Å–µ–∫—Ç–æ—Ä –ø—Ä–∏–≤–ª–µ–∫–∞–µ—Ç —Ä–µ–∫–æ—Ä–¥–Ω—ã–µ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏. –ù–æ–≤—ã–µ —Ä–µ—à–µ–Ω–∏—è –≤ –æ–±–ª–∞—Å—Ç–∏ –≤–æ–∑–æ–±–Ω–æ–≤–ª—è–µ–º–æ–π —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∏ –∏ —É—Å—Ç–æ–π—á–∏–≤–æ–≥–æ —Ä–∞–∑–≤–∏—Ç–∏—è –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –≤–ø–µ—á–∞—Ç–ª—è—é—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã...',
                'source': 'EcoTech',
                'source_domain': 'ecotech.org',
                'published_at': '2025-09-25T11:30:00',
                'score': 0.85,
                'tags': ['green', 'ecology', 'sustainability', 'energy']
            }
        ]

    async def run_comprehensive_tests(self):
        """Run all comprehensive tests"""
        self.total_start_time = time.time()

        logger.info("üöÄ Starting Comprehensive Data Analysis Testing Suite")
        logger.info(f"‚è∞ Start time: {datetime.now()}")
        logger.info(f"üêç Python version: {sys.version}")
        logger.info(f"üìÅ Working directory: {os.getcwd()}")

        # Check API key
        api_key = os.getenv('OPENAI_API_KEY')
        if api_key:
            logger.info(f"üîë OpenAI API Key: {api_key[:8]}***{api_key[-4:]}")
        else:
            logger.error("‚ùå OPENAI_API_KEY not found!")
            return

        # Run all test scenarios
        await self.test_deep_analysis_scenarios()
        await self.test_summarization_scenarios()
        await self.test_aggregation_scenarios()
        await self.test_filtering_scenarios()
        await self.test_insights_scenarios()
        await self.test_sentiment_scenarios()
        await self.test_topics_scenarios()

        # Generate comprehensive report
        self.generate_comprehensive_report()

    async def test_deep_analysis_scenarios(self):
        """Test deep analysis with different scenarios"""
        logger.info("=" * 60)
        logger.info("üß† TESTING DEEP ANALYSIS SCENARIOS")
        logger.info("=" * 60)

        scenarios = [
            {
                'name': 'Tech Innovation Analysis',
                'query': '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∏–Ω–Ω–æ–≤–∞—Ü–∏–∏',
                'timeframe': '7d',
                'data': self.test_data['tech_articles']
            },
            {
                'name': 'Market Trends Analysis',
                'query': '—Ä—ã–Ω–æ—á–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã',
                'timeframe': '14d',
                'data': self.test_data['market_articles']
            },
            {
                'name': 'Cross-Industry Analysis',
                'query': '—Ü–∏—Ñ—Ä–æ–≤–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è',
                'timeframe': '30d',
                'data': self.test_data['tech_articles'] + self.test_data['general_articles']
            }
        ]

        for scenario in scenarios:
            await self.test_analysis_scenario(scenario)

    async def test_analysis_scenario(self, scenario: Dict[str, Any]):
        """Test a specific analysis scenario"""
        logger.info(f"üî¨ Testing scenario: {scenario['name']}")

        try:
            # Import and test
            from data_analysis_processor import analyze_data

            start_time = time.time()
            result = await analyze_data(
                query=scenario['query'],
                timeframe=scenario['timeframe']
            )
            processing_time = time.time() - start_time

            if result.success:
                logger.info(f"‚úÖ {scenario['name']} - SUCCESS")
                logger.info(f"‚è±Ô∏è Processing time: {processing_time:.2f}s")
                logger.info(f"üìä Articles analyzed: {result.metadata.get('articles_count', 0)}")

                # Validate result structure
                if 'analysis' in result.data:
                    analysis_length = len(result.data['analysis']) if result.data['analysis'] else 0
                    logger.info(f"üìÑ Analysis length: {analysis_length} characters")

                    if analysis_length > 100:
                        logger.info(f"üìã Analysis preview: {result.data['analysis'][:200]}...")
                    else:
                        logger.warning("‚ö†Ô∏è Analysis seems too short")

                self.test_results[f"analyze_{scenario['name']}"] = {
                    'status': 'PASSED',
                    'processing_time': processing_time,
                    'details': result.metadata
                }
            else:
                logger.error(f"‚ùå {scenario['name']} - FAILED: {result.error}")
                self.test_results[f"analyze_{scenario['name']}"] = {
                    'status': 'FAILED',
                    'error': result.error
                }

        except Exception as e:
            logger.error(f"‚ùå {scenario['name']} - EXCEPTION: {str(e)}")
            self.test_results[f"analyze_{scenario['name']}"] = {
                'status': 'ERROR',
                'error': str(e)
            }

    async def test_summarization_scenarios(self):
        """Test summarization with different lengths and topics"""
        logger.info("=" * 60)
        logger.info("üìã TESTING SUMMARIZATION SCENARIOS")
        logger.info("=" * 60)

        scenarios = [
            {
                'name': 'Short Tech Summary',
                'topic': '–ò–ò —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏',
                'length': 'short',
                'timeframe': '7d'
            },
            {
                'name': 'Medium Market Summary',
                'topic': '—Ä—ã–Ω–æ—á–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞',
                'length': 'medium',
                'timeframe': '14d'
            },
            {
                'name': 'Long Detailed Summary',
                'topic': '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–Ω–¥—ã',
                'length': 'long',
                'timeframe': '30d'
            },
            {
                'name': 'Ultra Detailed Summary',
                'topic': '—Ü–∏—Ñ—Ä–æ–≤–∞—è —ç–∫–æ–Ω–æ–º–∏–∫–∞',
                'length': 'detailed',
                'timeframe': '7d'
            }
        ]

        for scenario in scenarios:
            await self.test_summarization_scenario(scenario)

    async def test_summarization_scenario(self, scenario: Dict[str, Any]):
        """Test a specific summarization scenario"""
        logger.info(f"üìù Testing summarization: {scenario['name']}")

        try:
            from data_analysis_processor import summarize_data

            start_time = time.time()
            result = await summarize_data(
                topic=scenario['topic'],
                length=scenario['length'],
                timeframe=scenario['timeframe']
            )
            processing_time = time.time() - start_time

            if result.success:
                logger.info(f"‚úÖ {scenario['name']} - SUCCESS")
                logger.info(f"‚è±Ô∏è Processing time: {processing_time:.2f}s")

                summary = result.data.get('summary', '')
                word_count = result.data.get('word_count', 0)

                logger.info(f"üìä Word count: {word_count}")
                logger.info(f"üìè Length setting: {scenario['length']}")

                if summary:
                    logger.info(f"üìã Summary preview: {summary[:150]}...")

                # Validate length appropriateness
                expected_ranges = {
                    'short': (50, 300),
                    'medium': (200, 600),
                    'long': (400, 1000),
                    'detailed': (600, 1500)
                }

                expected_range = expected_ranges.get(scenario['length'], (100, 500))
                if expected_range[0] <= word_count <= expected_range[1]:
                    logger.info(f"‚úÖ Word count within expected range: {expected_range}")
                else:
                    logger.warning(f"‚ö†Ô∏è Word count outside expected range: {expected_range}")

                self.test_results[f"summarize_{scenario['name']}"] = {
                    'status': 'PASSED',
                    'processing_time': processing_time,
                    'word_count': word_count,
                    'details': result.metadata
                }
            else:
                logger.error(f"‚ùå {scenario['name']} - FAILED: {result.error}")
                self.test_results[f"summarize_{scenario['name']}"] = {
                    'status': 'FAILED',
                    'error': result.error
                }

        except Exception as e:
            logger.error(f"‚ùå {scenario['name']} - EXCEPTION: {str(e)}")
            self.test_results[f"summarize_{scenario['name']}"] = {
                'status': 'ERROR',
                'error': str(e)
            }

    async def test_aggregation_scenarios(self):
        """Test data aggregation scenarios"""
        logger.info("=" * 60)
        logger.info("üìä TESTING AGGREGATION SCENARIOS")
        logger.info("=" * 60)

        scenarios = [
            {
                'name': 'Source Aggregation by Date',
                'metric': '–∏—Å—Ç–æ—á–Ω–∏–∫–∏',
                'groupby': '–¥–∞—Ç–∞',
                'query': '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏',
                'timeframe': '7d'
            },
            {
                'name': 'Content Aggregation by Source',
                'metric': '–∫–æ–Ω—Ç–µ–Ω—Ç',
                'groupby': '–∏—Å—Ç–æ—á–Ω–∏–∫',
                'query': '—Ä—ã–Ω–æ–∫',
                'timeframe': '14d'
            },
            {
                'name': 'Topic Aggregation by Time',
                'metric': '—Ç–µ–º—ã',
                'groupby': '–≤—Ä–µ–º—è',
                'query': '–∏–Ω–Ω–æ–≤–∞—Ü–∏–∏',
                'timeframe': '30d'
            }
        ]

        for scenario in scenarios:
            await self.test_aggregation_scenario(scenario)

    async def test_aggregation_scenario(self, scenario: Dict[str, Any]):
        """Test a specific aggregation scenario"""
        logger.info(f"üìà Testing aggregation: {scenario['name']}")

        try:
            from data_analysis_processor import aggregate_data

            start_time = time.time()
            result = await aggregate_data(
                metric=scenario['metric'],
                groupby=scenario['groupby'],
                query=scenario['query'],
                timeframe=scenario['timeframe']
            )
            processing_time = time.time() - start_time

            if result.success:
                logger.info(f"‚úÖ {scenario['name']} - SUCCESS")
                logger.info(f"‚è±Ô∏è Processing time: {processing_time:.2f}s")

                if 'aggregation_analysis' in result.data:
                    analysis = result.data['aggregation_analysis']
                    logger.info(f"üìä Aggregation analysis length: {len(analysis) if analysis else 0}")
                    if analysis:
                        logger.info(f"üìã Analysis preview: {analysis[:150]}...")

                self.test_results[f"aggregate_{scenario['name']}"] = {
                    'status': 'PASSED',
                    'processing_time': processing_time,
                    'details': result.metadata
                }
            else:
                logger.error(f"‚ùå {scenario['name']} - FAILED: {result.error}")
                self.test_results[f"aggregate_{scenario['name']}"] = {
                    'status': 'FAILED',
                    'error': result.error
                }

        except Exception as e:
            logger.error(f"‚ùå {scenario['name']} - EXCEPTION: {str(e)}")
            self.test_results[f"aggregate_{scenario['name']}"] = {
                'status': 'ERROR',
                'error': str(e)
            }

    async def test_filtering_scenarios(self):
        """Test smart filtering scenarios"""
        logger.info("=" * 60)
        logger.info("üîç TESTING FILTERING SCENARIOS")
        logger.info("=" * 60)

        scenarios = [
            {
                'name': 'Filter by Source Domain',
                'criteria': '–∏—Å—Ç–æ—á–Ω–∏–∫',
                'value': 'technews.com',
                'query': '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏',
                'timeframe': '7d'
            },
            {
                'name': 'Filter by Content Keywords',
                'criteria': '—Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ',
                'value': '–ò–ò',
                'query': '–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç',
                'timeframe': '14d'
            },
            {
                'name': 'Filter by Title Keywords',
                'criteria': '–Ω–∞–∑–≤–∞–Ω–∏–µ',
                'value': '—Ä—ã–Ω–æ–∫',
                'query': '—Ä—ã–Ω–æ—á–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞',
                'timeframe': '30d'
            }
        ]

        for scenario in scenarios:
            await self.test_filtering_scenario(scenario)

    async def test_filtering_scenario(self, scenario: Dict[str, Any]):
        """Test a specific filtering scenario"""
        logger.info(f"üîé Testing filtering: {scenario['name']}")

        try:
            from data_analysis_processor import filter_data

            start_time = time.time()
            result = await filter_data(
                criteria=scenario['criteria'],
                value=scenario['value'],
                query=scenario['query'],
                timeframe=scenario['timeframe']
            )
            processing_time = time.time() - start_time

            if result.success:
                logger.info(f"‚úÖ {scenario['name']} - SUCCESS")
                logger.info(f"‚è±Ô∏è Processing time: {processing_time:.2f}s")

                filter_stats = result.data.get('filter_stats', {})
                logger.info(f"üìä Original count: {filter_stats.get('original_count', 0)}")
                logger.info(f"üìä Filtered count: {filter_stats.get('filtered_count', 0)}")
                logger.info(f"üìä Filter ratio: {filter_stats.get('filter_ratio', 0):.2%}")

                if 'filtering_analysis' in result.data:
                    analysis = result.data['filtering_analysis']
                    if analysis:
                        logger.info(f"üìã Analysis preview: {analysis[:150]}...")

                self.test_results[f"filter_{scenario['name']}"] = {
                    'status': 'PASSED',
                    'processing_time': processing_time,
                    'filter_stats': filter_stats
                }
            else:
                logger.error(f"‚ùå {scenario['name']} - FAILED: {result.error}")
                self.test_results[f"filter_{scenario['name']}"] = {
                    'status': 'FAILED',
                    'error': result.error
                }

        except Exception as e:
            logger.error(f"‚ùå {scenario['name']} - EXCEPTION: {str(e)}")
            self.test_results[f"filter_{scenario['name']}"] = {
                'status': 'ERROR',
                'error': str(e)
            }

    async def test_insights_scenarios(self):
        """Test business insights generation scenarios"""
        logger.info("=" * 60)
        logger.info("üí° TESTING INSIGHTS SCENARIOS")
        logger.info("=" * 60)

        scenarios = [
            {
                'name': 'Tech Market Insights',
                'topic': '—Ä—ã–Ω–æ–∫ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π',
                'timeframe': '7d'
            },
            {
                'name': 'AI Industry Insights',
                'topic': '–∏–Ω–¥—É—Å—Ç—Ä–∏—è –ò–ò',
                'timeframe': '14d'
            },
            {
                'name': 'Investment Opportunities',
                'topic': '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏',
                'timeframe': '30d'
            }
        ]

        for scenario in scenarios:
            await self.test_insights_scenario(scenario)

    async def test_insights_scenario(self, scenario: Dict[str, Any]):
        """Test a specific insights scenario"""
        logger.info(f"üíº Testing insights: {scenario['name']}")

        try:
            from data_analysis_processor import generate_insights

            start_time = time.time()
            result = await generate_insights(
                topic=scenario['topic'],
                timeframe=scenario['timeframe']
            )
            processing_time = time.time() - start_time

            if result.success:
                logger.info(f"‚úÖ {scenario['name']} - SUCCESS")
                logger.info(f"‚è±Ô∏è Processing time: {processing_time:.2f}s")

                insights = result.data.get('insights', '')
                confidence = result.data.get('confidence_score', 0)

                logger.info(f"üìä Confidence score: {confidence:.2f}")

                if insights:
                    logger.info(f"üìã Insights preview: {insights[:150]}...")

                self.test_results[f"insights_{scenario['name']}"] = {
                    'status': 'PASSED',
                    'processing_time': processing_time,
                    'confidence_score': confidence
                }
            else:
                logger.error(f"‚ùå {scenario['name']} - FAILED: {result.error}")
                self.test_results[f"insights_{scenario['name']}"] = {
                    'status': 'FAILED',
                    'error': result.error
                }

        except Exception as e:
            logger.error(f"‚ùå {scenario['name']} - EXCEPTION: {str(e)}")
            self.test_results[f"insights_{scenario['name']}"] = {
                'status': 'ERROR',
                'error': str(e)
            }

    async def test_sentiment_scenarios(self):
        """Test sentiment analysis scenarios"""
        logger.info("=" * 60)
        logger.info("üòä TESTING SENTIMENT SCENARIOS")
        logger.info("=" * 60)

        scenarios = [
            {
                'name': 'Tech News Sentiment',
                'query': '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –Ω–æ–≤–æ—Å—Ç–∏',
                'timeframe': '7d'
            },
            {
                'name': 'Market Sentiment',
                'query': '—Ä—ã–Ω–æ—á–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è',
                'timeframe': '14d'
            },
            {
                'name': 'Investment Sentiment',
                'query': '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–π –∫–ª–∏–º–∞—Ç',
                'timeframe': '30d'
            }
        ]

        for scenario in scenarios:
            await self.test_sentiment_scenario(scenario)

    async def test_sentiment_scenario(self, scenario: Dict[str, Any]):
        """Test a specific sentiment scenario"""
        logger.info(f"üòä Testing sentiment: {scenario['name']}")

        try:
            from data_analysis_processor import analyze_sentiment

            start_time = time.time()
            result = await analyze_sentiment(
                query=scenario['query'],
                timeframe=scenario['timeframe']
            )
            processing_time = time.time() - start_time

            if result.success:
                logger.info(f"‚úÖ {scenario['name']} - SUCCESS")
                logger.info(f"‚è±Ô∏è Processing time: {processing_time:.2f}s")

                sentiment_metrics = result.data.get('sentiment_metrics', {})
                confidence = result.data.get('confidence_level', 0)

                logger.info(f"üìä Average sentiment: {sentiment_metrics.get('average_sentiment', 0):.2f}")
                logger.info(f"üìä Positive ratio: {sentiment_metrics.get('positive_ratio', 0):.2%}")
                logger.info(f"üìä Confidence level: {confidence:.2f}")

                if 'sentiment_analysis' in result.data:
                    analysis = result.data['sentiment_analysis']
                    if analysis:
                        logger.info(f"üìã Analysis preview: {analysis[:150]}...")

                self.test_results[f"sentiment_{scenario['name']}"] = {
                    'status': 'PASSED',
                    'processing_time': processing_time,
                    'sentiment_metrics': sentiment_metrics
                }
            else:
                logger.error(f"‚ùå {scenario['name']} - FAILED: {result.error}")
                self.test_results[f"sentiment_{scenario['name']}"] = {
                    'status': 'FAILED',
                    'error': result.error
                }

        except Exception as e:
            logger.error(f"‚ùå {scenario['name']} - EXCEPTION: {str(e)}")
            self.test_results[f"sentiment_{scenario['name']}"] = {
                'status': 'ERROR',
                'error': str(e)
            }

    async def test_topics_scenarios(self):
        """Test topic modeling scenarios"""
        logger.info("=" * 60)
        logger.info("üè∑Ô∏è TESTING TOPICS SCENARIOS")
        logger.info("=" * 60)

        scenarios = [
            {
                'name': 'Technology Topics',
                'scope': '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–Ω–¥—ã',
                'timeframe': '7d'
            },
            {
                'name': 'Market Topics',
                'scope': '—Ä—ã–Ω–æ—á–Ω–∞—è –¥–∏–Ω–∞–º–∏–∫–∞',
                'timeframe': '14d'
            },
            {
                'name': 'Innovation Topics',
                'scope': '–∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è',
                'timeframe': '30d'
            }
        ]

        for scenario in scenarios:
            await self.test_topics_scenario(scenario)

    async def test_topics_scenario(self, scenario: Dict[str, Any]):
        """Test a specific topics scenario"""
        logger.info(f"üè∑Ô∏è Testing topics: {scenario['name']}")

        try:
            from data_analysis_processor import analyze_topics

            start_time = time.time()
            result = await analyze_topics(
                scope=scenario['scope'],
                timeframe=scenario['timeframe']
            )
            processing_time = time.time() - start_time

            if result.success:
                logger.info(f"‚úÖ {scenario['name']} - SUCCESS")
                logger.info(f"‚è±Ô∏è Processing time: {processing_time:.2f}s")

                topic_metrics = result.data.get('topic_metrics', {})
                trend_indicators = result.data.get('trend_indicators', {})

                logger.info(f"üìä Topic diversity: {topic_metrics.get('topic_diversity', 0):.2f}")
                logger.info(f"üìä Keyword density: {topic_metrics.get('keyword_density', 0):.2f}")

                if 'topics_analysis' in result.data:
                    analysis = result.data['topics_analysis']
                    if analysis:
                        logger.info(f"üìã Analysis preview: {analysis[:150]}...")

                self.test_results[f"topics_{scenario['name']}"] = {
                    'status': 'PASSED',
                    'processing_time': processing_time,
                    'topic_metrics': topic_metrics
                }
            else:
                logger.error(f"‚ùå {scenario['name']} - FAILED: {result.error}")
                self.test_results[f"topics_{scenario['name']}"] = {
                    'status': 'FAILED',
                    'error': result.error
                }

        except Exception as e:
            logger.error(f"‚ùå {scenario['name']} - EXCEPTION: {str(e)}")
            self.test_results[f"topics_{scenario['name']}"] = {
                'status': 'ERROR',
                'error': str(e)
            }

    def generate_comprehensive_report(self):
        """Generate comprehensive test report"""
        total_time = time.time() - self.total_start_time if self.total_start_time else 0

        logger.info("=" * 80)
        logger.info("üìã COMPREHENSIVE TEST RESULTS REPORT")
        logger.info("=" * 80)

        # Count results by status
        passed = sum(1 for result in self.test_results.values() if result['status'] == 'PASSED')
        failed = sum(1 for result in self.test_results.values() if result['status'] == 'FAILED')
        errors = sum(1 for result in self.test_results.values() if result['status'] == 'ERROR')
        total = len(self.test_results)

        logger.info(f"üìä OVERALL STATISTICS:")
        logger.info(f"   ‚úÖ Passed: {passed}/{total} ({passed/total*100:.1f}%)")
        logger.info(f"   ‚ùå Failed: {failed}/{total} ({failed/total*100:.1f}%)")
        logger.info(f"   üö´ Errors: {errors}/{total} ({errors/total*100:.1f}%)")
        logger.info(f"   ‚è±Ô∏è Total time: {total_time:.2f}s")

        # Detailed results by command type
        command_types = ['analyze', 'summarize', 'aggregate', 'filter', 'insights', 'sentiment', 'topics']

        logger.info(f"\nüìã RESULTS BY COMMAND TYPE:")
        for cmd_type in command_types:
            cmd_results = {k: v for k, v in self.test_results.items() if k.startswith(cmd_type)}
            if cmd_results:
                cmd_passed = sum(1 for r in cmd_results.values() if r['status'] == 'PASSED')
                cmd_total = len(cmd_results)
                success_rate = cmd_passed / cmd_total * 100 if cmd_total > 0 else 0

                status_emoji = "‚úÖ" if success_rate == 100 else "‚ö†Ô∏è" if success_rate >= 50 else "‚ùå"
                logger.info(f"   {status_emoji} /{cmd_type}: {cmd_passed}/{cmd_total} ({success_rate:.1f}%)")

        # Individual test results
        logger.info(f"\nüìã INDIVIDUAL TEST RESULTS:")
        for test_name, result in self.test_results.items():
            status_emoji = {"PASSED": "‚úÖ", "FAILED": "‚ùå", "ERROR": "üö´"}[result['status']]

            time_info = f" ({result.get('processing_time', 0):.2f}s)" if 'processing_time' in result else ""
            error_info = f" - {result['error']}" if result['status'] != 'PASSED' and 'error' in result else ""

            logger.info(f"   {status_emoji} {test_name}{time_info}{error_info}")

        # Performance analysis
        if passed > 0:
            processing_times = [r.get('processing_time', 0) for r in self.test_results.values() if r['status'] == 'PASSED']
            if processing_times:
                avg_time = sum(processing_times) / len(processing_times)
                max_time = max(processing_times)
                min_time = min(processing_times)

                logger.info(f"\nüìä PERFORMANCE ANALYSIS:")
                logger.info(f"   ‚è±Ô∏è Average processing time: {avg_time:.2f}s")
                logger.info(f"   ‚è±Ô∏è Max processing time: {max_time:.2f}s")
                logger.info(f"   ‚è±Ô∏è Min processing time: {min_time:.2f}s")

        # Final status
        logger.info(f"\nüéØ FINAL STATUS:")
        if passed == total:
            logger.info("üéâ ALL TESTS PASSED! Data analysis system is fully operational.")
        elif passed >= total * 0.8:
            logger.info(f"‚úÖ MOSTLY SUCCESSFUL! {passed}/{total} tests passed. Minor issues detected.")
        elif passed >= total * 0.5:
            logger.info(f"‚ö†Ô∏è PARTIALLY SUCCESSFUL! {passed}/{total} tests passed. Significant issues need attention.")
        else:
            logger.info(f"‚ùå MAJOR ISSUES DETECTED! Only {passed}/{total} tests passed. System needs repair.")

        # Save results to file
        report_data = {
            'timestamp': datetime.now().isoformat(),
            'total_time': total_time,
            'summary': {
                'total_tests': total,
                'passed': passed,
                'failed': failed,
                'errors': errors,
                'success_rate': passed / total * 100 if total > 0 else 0
            },
            'detailed_results': self.test_results
        }

        try:
            with open('data_analysis_test_report.json', 'w', encoding='utf-8') as f:
                json.dump(report_data, f, ensure_ascii=False, indent=2)
            logger.info(f"üìÑ Detailed report saved to: data_analysis_test_report.json")
        except Exception as e:
            logger.error(f"‚ùå Failed to save report: {e}")

        logger.info("=" * 80)


async def main():
    """Main test execution"""
    test_suite = DataAnalysisTestSuite()
    await test_suite.run_comprehensive_tests()


if __name__ == "__main__":
    asyncio.run(main())