"""
System report generator for RSS news aggregation system
"""

import os
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, Optional
import requests
import json
import asyncio

logger = logging.getLogger(__name__)


def generate_report(client, period_hours: int = 8, format: str = "markdown") -> str:
    """Generate comprehensive system report"""

    # Calculate time period
    now = datetime.now()
    period_start = now - timedelta(hours=period_hours)

    # Collect statistics
    stats = collect_statistics(client, period_start, now)

    # Format report
    if format == "html":
        return format_html_report(stats, period_hours)
    else:
        return format_markdown_report(stats, period_hours)


async def generate_enhanced_telegram_report(client, period_hours: int = 8) -> str:
    """Generate enhanced report with GPT analysis for Telegram"""

    # Calculate time period
    now = datetime.now()
    period_start = now - timedelta(hours=period_hours)

    # Collect statistics
    stats = collect_statistics(client, period_start, now)

    # Generate base report
    base_report = format_markdown_report(stats, period_hours)

    # Add GPT analysis
    gpt_analysis = await generate_gpt5_analysis(stats, period_hours)

    # Combine reports
    enhanced_report = f"{base_report}\n\n{gpt_analysis}"

    return enhanced_report


def collect_statistics(client, period_start: datetime, period_end: datetime) -> Dict[str, Any]:
    """Collect all system statistics"""

    stats = {
        'timestamp': period_end.isoformat(),
        'period_hours': (period_end - period_start).total_seconds() / 3600,
        'feeds': {},
        'raw_articles': {},
        'stage6': {},
        'stage7': {},
        'pinecone': {}
    }

    try:
        with client._cursor() as cur:
            # Feed statistics
            cur.execute("SELECT COUNT(*) FROM feeds WHERE status = 'active'")
            stats['feeds']['active'] = cur.fetchone()[0]

            cur.execute("SELECT COUNT(*) FROM feeds")
            stats['feeds']['total'] = cur.fetchone()[0]

            # Raw articles by status
            cur.execute("""
                SELECT status, COUNT(*)
                FROM raw
                WHERE status IS NOT NULL
                GROUP BY status
            """)
            for status, count in cur.fetchall():
                stats['raw_articles'][status] = count

            # Articles in period
            cur.execute("""
                SELECT status, COUNT(*)
                FROM raw
                WHERE created_at >= %s AND created_at <= %s
                GROUP BY status
            """, (period_start, period_end))

            period_stats = {}
            for status, count in cur.fetchall():
                period_stats[status] = count
            stats['raw_articles']['period'] = period_stats

            # Stage 6 statistics
            cur.execute("SELECT COUNT(*) FROM articles_index WHERE COALESCE(ready_for_chunking, false) = true")
            stats['stage6']['ready_for_chunking'] = cur.fetchone()[0]

            cur.execute("SELECT COUNT(*) FROM articles_index WHERE COALESCE(chunking_completed, false) = true")
            stats['stage6']['chunking_completed'] = cur.fetchone()[0]

            cur.execute("SELECT COUNT(*) FROM article_chunks")
            stats['stage6']['total_chunks'] = cur.fetchone()[0]

            # New chunks in period
            cur.execute("""
                SELECT COUNT(*) FROM article_chunks
                WHERE created_at >= %s AND created_at <= %s
            """, (period_start, period_end))
            stats['stage6']['new_chunks_period'] = cur.fetchone()[0]

            # Stage 7 statistics
            cur.execute("SELECT COUNT(*) FROM article_chunks WHERE fts_vector IS NOT NULL")
            stats['stage7']['fts_indexed'] = cur.fetchone()[0]

            cur.execute("SELECT COUNT(*) FROM article_chunks WHERE embedding IS NOT NULL")
            stats['stage7']['embeddings_stored'] = cur.fetchone()[0]

            cur.execute("SELECT COUNT(*) FROM article_chunks WHERE fts_vector IS NULL")
            stats['stage7']['fts_missing'] = cur.fetchone()[0]

            cur.execute("SELECT COUNT(*) FROM article_chunks WHERE embedding IS NULL")
            stats['stage7']['embeddings_missing'] = cur.fetchone()[0]

    except Exception as e:
        logger.error(f"Database statistics collection failed: {e}")
        stats['error'] = str(e)

    # Pinecone statistics
    try:
        stats['pinecone'] = collect_pinecone_stats()
    except Exception as e:
        logger.warning(f"Pinecone statistics collection failed: {e}")
        stats['pinecone'] = {'error': str(e)}

    return stats


def collect_pinecone_stats() -> Dict[str, Any]:
    """Collect Pinecone index statistics"""

    pinecone_stats = {}

    try:
        # Check if Pinecone is configured
        api_key = os.getenv('PINECONE_API_KEY')
        index_name = os.getenv('PINECONE_INDEX')
        region = os.getenv('PINECONE_REGION', 'us-east-1-aws')

        if not api_key or not index_name:
            return {'status': 'not_configured'}

        # Try to get Pinecone stats using REST API
        host = f"{index_name}-{region}.svc.{region}.pinecone.io"
        url = f"https://{host}/describe_index_stats"

        headers = {
            'Api-Key': api_key,
            'Content-Type': 'application/json'
        }

        response = requests.get(url, headers=headers, timeout=10)

        if response.status_code == 200:
            data = response.json()
            pinecone_stats = {
                'status': 'connected',
                'total_vector_count': data.get('totalVectorCount', 0),
                'dimension': data.get('dimension', 0),
                'index_fullness': data.get('indexFullness', 0),
                'namespaces': data.get('namespaces', {})
            }
        else:
            pinecone_stats = {
                'status': 'error',
                'error': f"HTTP {response.status_code}: {response.text[:200]}"
            }

    except requests.RequestException as e:
        pinecone_stats = {
            'status': 'connection_error',
            'error': str(e)
        }
    except Exception as e:
        pinecone_stats = {
            'status': 'error',
            'error': str(e)
        }

    return pinecone_stats


def format_markdown_report(stats: Dict[str, Any], period_hours: int) -> str:
    """Format report as Markdown"""

    report_time = datetime.fromisoformat(stats['timestamp']).strftime('%Y-%m-%d %H:%M:%S')

    # Calculate totals
    total_articles = sum(stats['raw_articles'].get(status, 0)
                        for status in ['stored', 'partial', 'duplicate', 'pending', 'processing', 'error'])

    period_total = sum(stats['raw_articles'].get('period', {}).values())

    # Processing rates
    chunks_total = stats['stage6']['total_chunks']
    fts_coverage = (stats['stage7']['fts_indexed'] / max(chunks_total, 1)) * 100
    emb_coverage = (stats['stage7']['embeddings_stored'] / max(chunks_total, 1)) * 100

    report = f"""ðŸ¤– **RSS News System Report**
ðŸ“… {report_time} (Period: {period_hours}h)

**ðŸ“Š Feeds Status**
â€¢ Active: {stats['feeds']['active']}/{stats['feeds']['total']}

**ðŸ“° Articles Overview**
â€¢ Total: {total_articles:,}
â€¢ New ({period_hours}h): {period_total:,}

**ðŸ“ˆ Processing Status**
â€¢ âœ… Stored: {stats['raw_articles'].get('stored', 0):,}
â€¢ â³ Pending: {stats['raw_articles'].get('pending', 0):,}
â€¢ ðŸ”„ Processing: {stats['raw_articles'].get('processing', 0):,}
â€¢ ðŸ“‹ Partial: {stats['raw_articles'].get('partial', 0):,}
â€¢ âŒ Errors: {stats['raw_articles'].get('error', 0):,}

**ðŸ”§ Stage 6 (Chunking)**
â€¢ Ready: {stats['stage6']['ready_for_chunking']:,}
â€¢ Completed: {stats['stage6']['chunking_completed']:,}
â€¢ Total chunks: {chunks_total:,}
â€¢ New chunks ({period_hours}h): {stats['stage6']['new_chunks_period']:,}

**ðŸ” Stage 7 (Indexing)**
â€¢ FTS indexed: {stats['stage7']['fts_indexed']:,}/{chunks_total:,} ({fts_coverage:.1f}%)
â€¢ Embeddings: {stats['stage7']['embeddings_stored']:,}/{chunks_total:,} ({emb_coverage:.1f}%)
"""

    # Pinecone section
    pc_stats = stats['pinecone']
    if pc_stats.get('status') == 'connected':
        report += f"""
**ðŸŒ² Pinecone Status**
â€¢ Vectors: {pc_stats.get('total_vector_count', 0):,}
â€¢ Dimension: {pc_stats.get('dimension', 0)}
â€¢ Fullness: {(pc_stats.get('index_fullness', 0) * 100):.1f}%"""
    elif pc_stats.get('status') == 'not_configured':
        report += "\n**ðŸŒ² Pinecone**: Not configured"
    else:
        report += f"\n**ðŸŒ² Pinecone**: âŒ {pc_stats.get('error', 'Unknown error')[:50]}"

    # Add period breakdown if there's activity
    period_stats = stats['raw_articles'].get('period', {})
    if period_total > 0:
        report += f"\n\n**ðŸ“Š Period Activity ({period_hours}h)**"
        for status, count in period_stats.items():
            if count > 0:
                report += f"\nâ€¢ {status}: {count:,}"

    return report


def format_html_report(stats: Dict[str, Any], period_hours: int) -> str:
    """Format report as HTML"""

    # Convert markdown to basic HTML
    markdown_report = format_markdown_report(stats, period_hours)

    # Simple markdown to HTML conversion
    html_report = markdown_report.replace('**', '<b>').replace('**', '</b>')
    html_report = html_report.replace('â€¢ ', 'â€¢ ')
    html_report = html_report.replace('\n', '<br>\n')

    return f"<pre>{html_report}</pre>"


async def generate_gpt5_analysis(stats: Dict[str, Any], period_hours: int) -> str:
    """Generate GPT-5 analysis of RSS system statistics in Russian"""

    try:
        # Check if OpenAI API key is available
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            return "âš ï¸ *GPT-5 Ð°Ð½Ð°Ð»Ð¸Ð· Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½:* OPENAI_API_KEY Ð½Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½"

        # Import OpenAI client
        try:
            from openai import AsyncOpenAI
        except ImportError:
            return "âš ï¸ *GPT-5 Ð°Ð½Ð°Ð»Ð¸Ð· Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½:* openai Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÐ° Ð½Ðµ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð°"

        # Prepare statistics summary for analysis
        total_articles = sum(stats['raw_articles'].get(status, 0)
                           for status in ['stored', 'partial', 'duplicate', 'pending', 'processing', 'error'])
        period_total = sum(stats['raw_articles'].get('period', {}).values())

        # Calculate key metrics
        success_rate = (stats['raw_articles'].get('stored', 0) / max(total_articles, 1)) * 100
        error_rate = (stats['raw_articles'].get('error', 0) / max(total_articles, 1)) * 100
        fts_coverage = (stats['stage7']['fts_indexed'] / max(stats['stage6']['total_chunks'], 1)) * 100

        # Create analysis prompt
        analysis_prompt = f"""
Ð¢Ñ‹ - Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸Ðº RSS Ð½Ð¾Ð²Ð¾ÑÑ‚Ð½Ð¾Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹. ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð·Ð° {period_hours} Ñ‡Ð°ÑÐ¾Ð² Ð¸ Ð´Ð°Ð¹ ÐºÑ€Ð°Ñ‚ÐºÐ¸Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ.

Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°:
- ÐÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ… Ñ„Ð¸Ð´Ð¾Ð²: {stats['feeds']['active']}/{stats['feeds']['total']}
- Ð’ÑÐµÐ³Ð¾ ÑÑ‚Ð°Ñ‚ÐµÐ¹: {total_articles:,}
- ÐÐ¾Ð²Ñ‹Ñ… ÑÑ‚Ð°Ñ‚ÐµÐ¹ Ð·Ð° Ð¿ÐµÑ€Ð¸Ð¾Ð´: {period_total}
- Ð£ÑÐ¿ÐµÑˆÐ½Ð¾ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾: {stats['raw_articles'].get('stored', 0)} ({success_rate:.1f}%)
- ÐžÑˆÐ¸Ð±Ð¾Ðº: {stats['raw_articles'].get('error', 0)} ({error_rate:.1f}%)
- Ð’ Ð¾Ñ‡ÐµÑ€ÐµÐ´Ð¸: {stats['raw_articles'].get('pending', 0)}
- Ð“Ð¾Ñ‚Ð¾Ð²Ð¾ Ðº Ñ‡Ð°Ð½ÐºÐ¸Ð½Ð³Ñƒ: {stats['stage6']['ready_for_chunking']}
- Ð—Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾ Ñ‡Ð°Ð½ÐºÐ¾Ð²: {stats['stage6']['chunking_completed']}
- Ð’ÑÐµÐ³Ð¾ Ñ‡Ð°Ð½ÐºÐ¾Ð²: {stats['stage6']['total_chunks']}
- FTS Ð¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ñ: {stats['stage7']['fts_indexed']}/{stats['stage6']['total_chunks']} ({fts_coverage:.1f}%)
- Embeddings: {stats['stage7']['embeddings_stored']}

Ð”Ð°Ð¹ ÐºÑ€Ð°Ñ‚ÐºÐ¸Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· (2-3 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ):
1. ÐžÐ±Ñ‰ÐµÐµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹
2. ÐžÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ð¸Ð»Ð¸ Ð´Ð¾ÑÑ‚Ð¸Ð¶ÐµÐ½Ð¸Ñ
3. Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸ÑŽ

ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¾ Ð¸ Ð¿Ð¾ Ð´ÐµÐ»Ñƒ, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ ÑÐ¼Ð¾Ð´Ð·Ð¸ Ð´Ð»Ñ Ð½Ð°Ð³Ð»ÑÐ´Ð½Ð¾ÑÑ‚Ð¸.
"""

        client = AsyncOpenAI(api_key=api_key)

        # GPT-5 Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ Responses API
        system_prompt = "Ð¢Ñ‹ - Ð¾Ð¿Ñ‹Ñ‚Ð½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸Ðº IT-ÑÐ¸ÑÑ‚ÐµÐ¼, ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽÑ‰Ð¸Ð¹ÑÑ Ð½Ð° RSS Ð°Ð³Ñ€ÐµÐ³Ð°Ñ‚Ð¾Ñ€Ð°Ñ… Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹."

        response = await client.responses.create(
            model="gpt-5",
            instructions=system_prompt,
            input=analysis_prompt,
            max_output_tokens=500
        )

        # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ñ‚ÐµÐºÑÑ‚ Ð¸Ð· Responses API (Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ñ‚Ð¾Ñ‚ Ð¶Ðµ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ Ñ‡Ñ‚Ð¾ Ð² main.py)
        analysis = getattr(response, "output_text", None)
        if not analysis:
            try:
                # Fallback Ðº ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ðµ .output[0].content[0].text
                parts = []
                output = getattr(response, "output", None) or []
                for item in output:
                    for content in getattr(item, "content", []) or []:
                        text = getattr(content, "text", None)
                        if text:
                            parts.append(text)
                analysis = "\n".join(parts)
            except Exception:
                analysis = None

        if not analysis:
            analysis = "ÐÐ½Ð°Ð»Ð¸Ð· Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½, Ð½Ð¾ Ñ‚ÐµÐºÑÑ‚ Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¸Ð·Ð²Ð»ÐµÑ‡ÑŒ"

        return f"ðŸ¤– **GPT-5 ÐÐ½Ð°Ð»Ð¸Ð·:**\n{analysis.strip()}"

    except Exception as e:
        logger.error(f"GPT-5 analysis failed: {e}")
        return f"âš ï¸ *GPT Ð°Ð½Ð°Ð»Ð¸Ð· Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½:* {str(e)[:100]}"


def send_telegram_report(report: str, format: str = "markdown") -> None:
    """Send report to Telegram"""

    bot_token = os.getenv('TELEGRAM_BOT_TOKEN')
    chat_id = os.getenv('TELEGRAM_CHAT_ID')

    if not bot_token or not chat_id:
        raise ValueError("TELEGRAM_BOT_TOKEN and TELEGRAM_CHAT_ID must be set")

    url = f"https://api.telegram.org/bot{bot_token}/sendMessage"

    # Prepare payload
    payload = {
        'chat_id': chat_id,
        'text': report,
        'parse_mode': 'Markdown' if format == 'markdown' else 'HTML',
        'disable_web_page_preview': True
    }

    # Truncate if too long (Telegram limit is 4096 chars)
    if len(report) > 4000:
        report = report[:3900] + "\n\n... (truncated)"
        payload['text'] = report

    # Send request
    response = requests.post(url, json=payload, timeout=30)

    if response.status_code != 200:
        raise Exception(f"Telegram API error: {response.status_code} - {response.text}")

    result = response.json()
    if not result.get('ok'):
        raise Exception(f"Telegram API error: {result.get('description', 'Unknown error')}")

    logger.info("Report sent to Telegram successfully")


async def send_enhanced_telegram_report(client, period_hours: int = 8) -> None:
    """Generate and send enhanced report with GPT analysis to Telegram"""

    try:
        # Generate enhanced report with GPT analysis
        report = await generate_enhanced_telegram_report(client, period_hours)

        # Send to Telegram
        send_telegram_report(report, format="markdown")

        logger.info("Enhanced report with GPT analysis sent to Telegram successfully")

    except Exception as e:
        logger.error(f"Failed to send enhanced Telegram report: {e}")
        raise