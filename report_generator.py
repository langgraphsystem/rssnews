"""
System report generator for RSS news aggregation system
"""

import os
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, Optional
import requests
import json
import asyncio
from html import escape as _html_escape

logger = logging.getLogger(__name__)


def generate_report(client, period_hours: int = 8, format: str = "html") -> str:
    """Generate comprehensive system report"""

    # Calculate time period
    now = datetime.now()
    period_start = now - timedelta(hours=period_hours)

    # Collect statistics
    stats = collect_statistics(client, period_start, now)

    # Format report
    if format == "html":
        return format_html_report(stats, period_hours)
    else:
        return format_markdown_report(stats, period_hours)


async def generate_enhanced_telegram_report(client, period_hours: int = 8) -> str:
    """Generate enhanced report with GPT analysis for Telegram"""

    # Calculate time period
    now = datetime.now()
    period_start = now - timedelta(hours=period_hours)

    # Collect statistics
    stats = collect_statistics(client, period_start, now)

    # Generate base report (HTML-safe)
    base_report_md = format_markdown_report(stats, period_hours)
    base_report = f"<pre>{_html_escape(base_report_md)}</pre>"

    # Add GPT analysis
    gpt_analysis = await generate_gpt5_analysis(stats, period_hours)

    # Convert GPT analysis to Telegram-safe HTML
    if isinstance(gpt_analysis, str):
        parts = gpt_analysis.split("\n", 1)
        gpt_body = parts[1] if len(parts) > 1 else gpt_analysis
    else:
        gpt_body = str(gpt_analysis)
    gpt_section = f"<b>ü§ñ GPT-5 –ê–Ω–∞–ª–∏–∑:</b>\n<pre>{_html_escape(gpt_body)}</pre>"

    # Combine reports (Telegram HTML - no <br> tags)
    enhanced_report = f"{base_report}\n\n{gpt_section}"

    return enhanced_report


def collect_statistics(client, period_start: datetime, period_end: datetime) -> Dict[str, Any]:
    """Collect all system statistics"""

    stats = {
        'timestamp': period_end.isoformat(),
        'period_hours': (period_end - period_start).total_seconds() / 3600,
        'feeds': {},
        'raw_articles': {},
        'stage6': {},
        'stage7': {},
        'pinecone': {}
    }

    try:
        with client._cursor() as cur:
            # Feed statistics
            cur.execute("SELECT COUNT(*) FROM feeds WHERE status = 'active'")
            stats['feeds']['active'] = cur.fetchone()[0]

            cur.execute("SELECT COUNT(*) FROM feeds")
            stats['feeds']['total'] = cur.fetchone()[0]

            # Raw articles by status
            cur.execute("""
                SELECT status, COUNT(*)
                FROM raw
                WHERE status IS NOT NULL
                GROUP BY status
            """)
            for status, count in cur.fetchall():
                stats['raw_articles'][status] = count

            # Articles in period
            cur.execute("""
                SELECT status, COUNT(*)
                FROM raw
                WHERE created_at >= %s AND created_at <= %s
                GROUP BY status
            """, (period_start, period_end))

            period_stats = {}
            for status, count in cur.fetchall():
                period_stats[status] = count
            stats['raw_articles']['period'] = period_stats

            # Stage 6 statistics
            cur.execute("SELECT COUNT(*) FROM articles_index WHERE COALESCE(ready_for_chunking, false) = true")
            stats['stage6']['ready_for_chunking'] = cur.fetchone()[0]

            cur.execute("SELECT COUNT(*) FROM articles_index WHERE COALESCE(chunking_completed, false) = true")
            stats['stage6']['chunking_completed'] = cur.fetchone()[0]

            cur.execute("SELECT COUNT(*) FROM article_chunks")
            stats['stage6']['total_chunks'] = cur.fetchone()[0]

            # New chunks in period
            cur.execute("""
                SELECT COUNT(*) FROM article_chunks
                WHERE created_at >= %s AND created_at <= %s
            """, (period_start, period_end))
            stats['stage6']['new_chunks_period'] = cur.fetchone()[0]

            # Stage 7 statistics
            cur.execute("SELECT COUNT(*) FROM article_chunks WHERE fts_vector IS NOT NULL")
            stats['stage7']['fts_indexed'] = cur.fetchone()[0]

            cur.execute("SELECT COUNT(*) FROM article_chunks WHERE embedding IS NOT NULL")
            stats['stage7']['embeddings_stored'] = cur.fetchone()[0]

            cur.execute("SELECT COUNT(*) FROM article_chunks WHERE fts_vector IS NULL")
            stats['stage7']['fts_missing'] = cur.fetchone()[0]

            cur.execute("SELECT COUNT(*) FROM article_chunks WHERE embedding IS NULL")
            stats['stage7']['embeddings_missing'] = cur.fetchone()[0]

    except Exception as e:
        logger.error(f"Database statistics collection failed: {e}")
        stats['error'] = str(e)

    # Pinecone statistics
    try:
        stats['pinecone'] = collect_pinecone_stats()
    except Exception as e:
        logger.warning(f"Pinecone statistics collection failed: {e}")
        stats['pinecone'] = {'error': str(e)}

    return stats


def collect_pinecone_stats() -> Dict[str, Any]:
    """Collect Pinecone index statistics"""

    pinecone_stats = {}

    try:
        # Check if Pinecone is configured
        api_key = os.getenv('PINECONE_API_KEY')
        index_name = os.getenv('PINECONE_INDEX')
        region = os.getenv('PINECONE_REGION', 'us-east-1-aws')

        if not api_key or not index_name:
            return {'status': 'not_configured'}

        # Try to get Pinecone stats using REST API
        host = f"{index_name}-{region}.svc.{region}.pinecone.io"
        url = f"https://{host}/describe_index_stats"

        headers = {
            'Api-Key': api_key,
            'Content-Type': 'application/json'
        }

        response = requests.get(url, headers=headers, timeout=10)

        if response.status_code == 200:
            data = response.json()
            pinecone_stats = {
                'status': 'connected',
                'total_vector_count': data.get('totalVectorCount', 0),
                'dimension': data.get('dimension', 0),
                'index_fullness': data.get('indexFullness', 0),
                'namespaces': data.get('namespaces', {})
            }
        else:
            pinecone_stats = {
                'status': 'error',
                'error': f"HTTP {response.status_code}: {response.text[:200]}"
            }

    except requests.RequestException as e:
        pinecone_stats = {
            'status': 'connection_error',
            'error': str(e)
        }
    except Exception as e:
        pinecone_stats = {
            'status': 'error',
            'error': str(e)
        }

    return pinecone_stats


def format_markdown_report(stats: Dict[str, Any], period_hours: int) -> str:
    """Format report as Markdown"""

    report_time = datetime.fromisoformat(stats['timestamp']).strftime('%Y-%m-%d %H:%M:%S')

    # Calculate totals
    total_articles = sum(stats['raw_articles'].get(status, 0)
                        for status in ['stored', 'partial', 'duplicate', 'pending', 'processing', 'error'])

    period_total = sum(stats['raw_articles'].get('period', {}).values())

    # Processing rates
    chunks_total = stats['stage6']['total_chunks']
    fts_coverage = (stats['stage7']['fts_indexed'] / max(chunks_total, 1)) * 100
    emb_coverage = (stats['stage7']['embeddings_stored'] / max(chunks_total, 1)) * 100

    report = f"""ü§ñ **RSS News System Report**
üìÖ {report_time} (Period: {period_hours}h)

**üìä Feeds Status**
‚Ä¢ Active: {stats['feeds']['active']}/{stats['feeds']['total']}

**üì∞ Articles Overview**
‚Ä¢ Total: {total_articles:,}
‚Ä¢ New ({period_hours}h): {period_total:,}

**üìà Processing Status**
‚Ä¢ ‚úÖ Stored: {stats['raw_articles'].get('stored', 0):,}
‚Ä¢ ‚è≥ Pending: {stats['raw_articles'].get('pending', 0):,}
‚Ä¢ üîÑ Processing: {stats['raw_articles'].get('processing', 0):,}
‚Ä¢ üìã Partial: {stats['raw_articles'].get('partial', 0):,}
‚Ä¢ ‚ùå Errors: {stats['raw_articles'].get('error', 0):,}

**üîß Stage 6 (Chunking)**
‚Ä¢ Ready: {stats['stage6']['ready_for_chunking']:,}
‚Ä¢ Completed: {stats['stage6']['chunking_completed']:,}
‚Ä¢ Total chunks: {chunks_total:,}
‚Ä¢ New chunks ({period_hours}h): {stats['stage6']['new_chunks_period']:,}

**üîç Stage 7 (Indexing)**
‚Ä¢ FTS indexed: {stats['stage7']['fts_indexed']:,}/{chunks_total:,} ({fts_coverage:.1f}%)
‚Ä¢ Embeddings: {stats['stage7']['embeddings_stored']:,}/{chunks_total:,} ({emb_coverage:.1f}%)
"""

    # Pinecone section
    pc_stats = stats['pinecone']
    if pc_stats.get('status') == 'connected':
        report += f"""
**üå≤ Pinecone Status**
‚Ä¢ Vectors: {pc_stats.get('total_vector_count', 0):,}
‚Ä¢ Dimension: {pc_stats.get('dimension', 0)}
‚Ä¢ Fullness: {(pc_stats.get('index_fullness', 0) * 100):.1f}%"""
    elif pc_stats.get('status') == 'not_configured':
        report += "\n**üå≤ Pinecone**: Not configured"
    else:
        report += f"\n**üå≤ Pinecone**: ‚ùå {pc_stats.get('error', 'Unknown error')[:50]}"

    # Add period breakdown if there's activity
    period_stats = stats['raw_articles'].get('period', {})
    if period_total > 0:
        report += f"\n\n**üìä Period Activity ({period_hours}h)**"
        for status, count in period_stats.items():
            if count > 0:
                report += f"\n‚Ä¢ {status}: {count:,}"

    return report


def format_html_report(stats: Dict[str, Any], period_hours: int) -> str:
    """Format report as HTML (safe-escaped, preformatted)."""
    markdown_report = format_markdown_report(stats, period_hours)
    return f"<pre>{_html_escape(markdown_report)}</pre>"


async def generate_gpt5_analysis(stats: Dict[str, Any], period_hours: int) -> str:
    """Generate GPT-5 analysis of RSS system statistics in Russian"""

    try:
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            return "‚ö†Ô∏è *GPT-5 –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω:* OPENAI_API_KEY –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"

        # Prepare statistics summary for analysis
        total_articles = sum(stats['raw_articles'].get(status, 0)
                           for status in ['stored', 'partial', 'duplicate', 'pending', 'processing', 'error'])
        period_total = sum(stats['raw_articles'].get('period', {}).values())

        # Calculate key metrics
        success_rate = (stats['raw_articles'].get('stored', 0) / max(total_articles, 1)) * 100
        error_rate = (stats['raw_articles'].get('error', 0) / max(total_articles, 1)) * 100
        fts_coverage = (stats['stage7']['fts_indexed'] / max(stats['stage6']['total_chunks'], 1)) * 100

        # Create analysis prompt
        analysis_prompt = f"""
–¢—ã - –∞–Ω–∞–ª–∏—Ç–∏–∫ RSS –Ω–æ–≤–æ—Å—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–∞–±–æ—Ç—ã —Å–∏—Å—Ç–µ–º—ã –∑–∞ {period_hours} —á–∞—Å–æ–≤ –∏ –¥–∞–π –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.

–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:
- –ê–∫—Ç–∏–≤–Ω—ã—Ö —Ñ–∏–¥–æ–≤: {stats['feeds']['active']}/{stats['feeds']['total']}
- –í—Å–µ–≥–æ —Å—Ç–∞—Ç–µ–π: {total_articles:,}
- –ù–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π –∑–∞ –ø–µ—Ä–∏–æ–¥: {period_total}
- –£—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {stats['raw_articles'].get('stored', 0)} ({success_rate:.1f}%)
- –û—à–∏–±–æ–∫: {stats['raw_articles'].get('error', 0)} ({error_rate:.1f}%)
- –í –æ—á–µ—Ä–µ–¥–∏: {stats['raw_articles'].get('pending', 0)}
- –ì–æ—Ç–æ–≤–æ –∫ —á–∞–Ω–∫–∏–Ω–≥—É: {stats['stage6']['ready_for_chunking']}
- –ó–∞–≤–µ—Ä—à–µ–Ω–æ —á–∞–Ω–∫–æ–≤: {stats['stage6']['chunking_completed']}
- –í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤: {stats['stage6']['total_chunks']}
- FTS –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è: {stats['stage7']['fts_indexed']}/{stats['stage6']['total_chunks']} ({fts_coverage:.1f}%)
- Embeddings: {stats['stage7']['embeddings_stored']}

–î–∞–π –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è):
1. –û–±—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã
2. –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏–ª–∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è
3. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é

–û—Ç–≤–µ—á–∞–π –∫–æ—Ä–æ—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –∏—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏.
"""

        system_prompt = "–¢—ã - –æ–ø—ã—Ç–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ IT-—Å–∏—Å—Ç–µ–º, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ RSS –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä–∞—Ö –∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –Ω–æ–≤–æ—Å—Ç–µ–π."

        try:
            from llm_helper import generate_response_text  # type: ignore
        except Exception:
            return "‚ö†Ô∏è *GPT-5 –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω:* llm_helper –Ω–µ –Ω–∞–π–¥–µ–Ω"

        try:
            analysis = await generate_response_text(
                analysis_prompt,
                instructions=system_prompt,
                model="gpt-5-nano-2025-08-07",
                store=True,
                max_output_tokens=800,
                retries=3,
                timeout=90.0,
            )
        except Exception as e:
            logger.error(f"GPT-5 analysis failed: {e}")
            return f"‚ö†Ô∏è *GPT-5 –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω:* {str(e)[:100]}"

        return f"ü§ñ **GPT-5 –ê–Ω–∞–ª–∏–∑:**\n{analysis}"

    except Exception as e:
        logger.error(f"GPT-5 analysis failed: {e}")
        return f"‚ö†Ô∏è *GPT-5 –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω:* {str(e)[:100]}"


def send_telegram_report(report: str, format: str = "html") -> None:
    """Send report to Telegram"""

    bot_token = os.getenv('TELEGRAM_BOT_TOKEN')
    chat_id = os.getenv('TELEGRAM_CHAT_ID')

    if not bot_token or not chat_id:
        raise ValueError("TELEGRAM_BOT_TOKEN and TELEGRAM_CHAT_ID must be set")

    url = f"https://api.telegram.org/bot{bot_token}/sendMessage"

    # Prepare payload
    payload = {
        'chat_id': chat_id,
        'text': report,
        'parse_mode': 'HTML' if format == 'html' else 'Markdown',
        'disable_web_page_preview': True
    }

    # Truncate if too long (Telegram limit is 4096 chars)
    if len(report) > 4000:
        report = report[:3900] + "\n\n... (truncated)"
        payload['text'] = report

    # Send request
    response = requests.post(url, json=payload, timeout=30)

    if response.status_code != 200:
        raise Exception(f"Telegram API error: {response.status_code} - {response.text}")

    result = response.json()
    if not result.get('ok'):
        raise Exception(f"Telegram API error: {result.get('description', 'Unknown error')}")

    logger.info("Report sent to Telegram successfully")


async def send_enhanced_telegram_report(client, period_hours: int = 8) -> None:
    """Generate and send enhanced report with GPT analysis to Telegram"""

    try:
        # Generate enhanced report with GPT analysis (HTML-safe)
        report = await generate_enhanced_telegram_report(client, period_hours)

        # Send to Telegram as HTML
        send_telegram_report(report, format="html")

        logger.info("Enhanced report with GPT analysis sent to Telegram successfully")

    except Exception as e:
        logger.error(f"Failed to send enhanced Telegram report: {e}")
        raise
