"""
System report generator for RSS news aggregation system
"""

import os
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, Optional
import requests
import json
import asyncio
from html import escape as _html_escape

logger = logging.getLogger(__name__)


def generate_report(client, period_hours: int = 8, format: str = "html") -> str:
    """Generate comprehensive system report"""

    # Calculate time period
    now = datetime.now()
    period_start = now - timedelta(hours=period_hours)

    # Collect statistics
    stats = collect_statistics(client, period_start, now)

    # Format report
    if format == "html":
        return format_html_report(stats, period_hours)
    else:
        return format_markdown_report(stats, period_hours)


async def generate_enhanced_telegram_report(client, period_hours: int = 8) -> str:
    """Generate enhanced report with GPT analysis for Telegram"""

    # Calculate time period
    now = datetime.now()
    period_start = now - timedelta(hours=period_hours)

    # Collect statistics
    stats = collect_statistics(client, period_start, now)

    # Generate base report (HTML-safe)
    base_report_md = format_markdown_report(stats, period_hours)
    base_report = f"<pre>{_html_escape(base_report_md)}</pre>"

    # Add GPT analysis
    gpt_analysis = await generate_gpt5_analysis(stats, period_hours)

    # Convert GPT analysis to HTML-safe section
    if isinstance(gpt_analysis, str):
        parts = gpt_analysis.split("\n", 1)
        gpt_body = parts[1] if len(parts) > 1 else gpt_analysis
    else:
        gpt_body = str(gpt_analysis)
    gpt_section = f"<b>ü§ñ GPT-5 –ê–Ω–∞–ª–∏–∑:</b><br><pre>{_html_escape(gpt_body)}</pre>"

    # Combine reports (HTML)
    enhanced_report = f"{base_report}<br>{gpt_section}"

    return enhanced_report


def collect_statistics(client, period_start: datetime, period_end: datetime) -> Dict[str, Any]:
    """Collect all system statistics"""

    stats = {
        'timestamp': period_end.isoformat(),
        'period_hours': (period_end - period_start).total_seconds() / 3600,
        'feeds': {},
        'raw_articles': {},
        'stage6': {},
        'stage7': {},
        'pinecone': {}
    }

    try:
        with client._cursor() as cur:
            # Feed statistics
            cur.execute("SELECT COUNT(*) FROM feeds WHERE status = 'active'")
            stats['feeds']['active'] = cur.fetchone()[0]

            cur.execute("SELECT COUNT(*) FROM feeds")
            stats['feeds']['total'] = cur.fetchone()[0]

            # Raw articles by status
            cur.execute("""
                SELECT status, COUNT(*)
                FROM raw
                WHERE status IS NOT NULL
                GROUP BY status
            """)
            for status, count in cur.fetchall():
                stats['raw_articles'][status] = count

            # Articles in period
            cur.execute("""
                SELECT status, COUNT(*)
                FROM raw
                WHERE created_at >= %s AND created_at <= %s
                GROUP BY status
            """, (period_start, period_end))

            period_stats = {}
            for status, count in cur.fetchall():
                period_stats[status] = count
            stats['raw_articles']['period'] = period_stats

            # Stage 6 statistics
            cur.execute("SELECT COUNT(*) FROM articles_index WHERE COALESCE(ready_for_chunking, false) = true")
            stats['stage6']['ready_for_chunking'] = cur.fetchone()[0]

            cur.execute("SELECT COUNT(*) FROM articles_index WHERE COALESCE(chunking_completed, false) = true")
            stats['stage6']['chunking_completed'] = cur.fetchone()[0]

            cur.execute("SELECT COUNT(*) FROM article_chunks")
            stats['stage6']['total_chunks'] = cur.fetchone()[0]

            # New chunks in period
            cur.execute("""
                SELECT COUNT(*) FROM article_chunks
                WHERE created_at >= %s AND created_at <= %s
            """, (period_start, period_end))
            stats['stage6']['new_chunks_period'] = cur.fetchone()[0]

            # Stage 7 statistics
            cur.execute("SELECT COUNT(*) FROM article_chunks WHERE fts_vector IS NOT NULL")
            stats['stage7']['fts_indexed'] = cur.fetchone()[0]

            cur.execute("SELECT COUNT(*) FROM article_chunks WHERE embedding IS NOT NULL")
            stats['stage7']['embeddings_stored'] = cur.fetchone()[0]

            cur.execute("SELECT COUNT(*) FROM article_chunks WHERE fts_vector IS NULL")
            stats['stage7']['fts_missing'] = cur.fetchone()[0]

            cur.execute("SELECT COUNT(*) FROM article_chunks WHERE embedding IS NULL")
            stats['stage7']['embeddings_missing'] = cur.fetchone()[0]

    except Exception as e:
        logger.error(f"Database statistics collection failed: {e}")
        stats['error'] = str(e)

    # Pinecone statistics
    try:
        stats['pinecone'] = collect_pinecone_stats()
    except Exception as e:
        logger.warning(f"Pinecone statistics collection failed: {e}")
        stats['pinecone'] = {'error': str(e)}

    return stats


def collect_pinecone_stats() -> Dict[str, Any]:
    """Collect Pinecone index statistics"""

    pinecone_stats = {}

    try:
        # Check if Pinecone is configured
        api_key = os.getenv('PINECONE_API_KEY')
        index_name = os.getenv('PINECONE_INDEX')
        region = os.getenv('PINECONE_REGION', 'us-east-1-aws')

        if not api_key or not index_name:
            return {'status': 'not_configured'}

        # Try to get Pinecone stats using REST API
        host = f"{index_name}-{region}.svc.{region}.pinecone.io"
        url = f"https://{host}/describe_index_stats"

        headers = {
            'Api-Key': api_key,
            'Content-Type': 'application/json'
        }

        response = requests.get(url, headers=headers, timeout=10)

        if response.status_code == 200:
            data = response.json()
            pinecone_stats = {
                'status': 'connected',
                'total_vector_count': data.get('totalVectorCount', 0),
                'dimension': data.get('dimension', 0),
                'index_fullness': data.get('indexFullness', 0),
                'namespaces': data.get('namespaces', {})
            }
        else:
            pinecone_stats = {
                'status': 'error',
                'error': f"HTTP {response.status_code}: {response.text[:200]}"
            }

    except requests.RequestException as e:
        pinecone_stats = {
            'status': 'connection_error',
            'error': str(e)
        }
    except Exception as e:
        pinecone_stats = {
            'status': 'error',
            'error': str(e)
        }

    return pinecone_stats


def format_markdown_report(stats: Dict[str, Any], period_hours: int) -> str:
    """Format report as Markdown"""

    report_time = datetime.fromisoformat(stats['timestamp']).strftime('%Y-%m-%d %H:%M:%S')

    # Calculate totals
    total_articles = sum(stats['raw_articles'].get(status, 0)
                        for status in ['stored', 'partial', 'duplicate', 'pending', 'processing', 'error'])

    period_total = sum(stats['raw_articles'].get('period', {}).values())

    # Processing rates
    chunks_total = stats['stage6']['total_chunks']
    fts_coverage = (stats['stage7']['fts_indexed'] / max(chunks_total, 1)) * 100
    emb_coverage = (stats['stage7']['embeddings_stored'] / max(chunks_total, 1)) * 100

    report = f"""ü§ñ **RSS News System Report**
üìÖ {report_time} (Period: {period_hours}h)

**üìä Feeds Status**
‚Ä¢ Active: {stats['feeds']['active']}/{stats['feeds']['total']}

**üì∞ Articles Overview**
‚Ä¢ Total: {total_articles:,}
‚Ä¢ New ({period_hours}h): {period_total:,}

**üìà Processing Status**
‚Ä¢ ‚úÖ Stored: {stats['raw_articles'].get('stored', 0):,}
‚Ä¢ ‚è≥ Pending: {stats['raw_articles'].get('pending', 0):,}
‚Ä¢ üîÑ Processing: {stats['raw_articles'].get('processing', 0):,}
‚Ä¢ üìã Partial: {stats['raw_articles'].get('partial', 0):,}
‚Ä¢ ‚ùå Errors: {stats['raw_articles'].get('error', 0):,}

**üîß Stage 6 (Chunking)**
‚Ä¢ Ready: {stats['stage6']['ready_for_chunking']:,}
‚Ä¢ Completed: {stats['stage6']['chunking_completed']:,}
‚Ä¢ Total chunks: {chunks_total:,}
‚Ä¢ New chunks ({period_hours}h): {stats['stage6']['new_chunks_period']:,}

**üîç Stage 7 (Indexing)**
‚Ä¢ FTS indexed: {stats['stage7']['fts_indexed']:,}/{chunks_total:,} ({fts_coverage:.1f}%)
‚Ä¢ Embeddings: {stats['stage7']['embeddings_stored']:,}/{chunks_total:,} ({emb_coverage:.1f}%)
"""

    # Pinecone section
    pc_stats = stats['pinecone']
    if pc_stats.get('status') == 'connected':
        report += f"""
**üå≤ Pinecone Status**
‚Ä¢ Vectors: {pc_stats.get('total_vector_count', 0):,}
‚Ä¢ Dimension: {pc_stats.get('dimension', 0)}
‚Ä¢ Fullness: {(pc_stats.get('index_fullness', 0) * 100):.1f}%"""
    elif pc_stats.get('status') == 'not_configured':
        report += "\n**üå≤ Pinecone**: Not configured"
    else:
        report += f"\n**üå≤ Pinecone**: ‚ùå {pc_stats.get('error', 'Unknown error')[:50]}"

    # Add period breakdown if there's activity
    period_stats = stats['raw_articles'].get('period', {})
    if period_total > 0:
        report += f"\n\n**üìä Period Activity ({period_hours}h)**"
        for status, count in period_stats.items():
            if count > 0:
                report += f"\n‚Ä¢ {status}: {count:,}"

    return report


def format_html_report(stats: Dict[str, Any], period_hours: int) -> str:
    """Format report as HTML (safe-escaped, preformatted)."""
    markdown_report = format_markdown_report(stats, period_hours)
    return f"<pre>{_html_escape(markdown_report)}</pre>"


async def generate_gpt5_analysis(stats: Dict[str, Any], period_hours: int) -> str:
    """Generate GPT-5 analysis of RSS system statistics in Russian"""

    try:
        # Check if OpenAI API key is available
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            return "‚ö†Ô∏è *GPT-5 –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω:* OPENAI_API_KEY –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"

        # Import OpenAI client
        try:
            from openai import AsyncOpenAI
        except ImportError:
            return "‚ö†Ô∏è *GPT-5 –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω:* openai –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞"

        # Prepare statistics summary for analysis
        total_articles = sum(stats['raw_articles'].get(status, 0)
                           for status in ['stored', 'partial', 'duplicate', 'pending', 'processing', 'error'])
        period_total = sum(stats['raw_articles'].get('period', {}).values())

        # Calculate key metrics
        success_rate = (stats['raw_articles'].get('stored', 0) / max(total_articles, 1)) * 100
        error_rate = (stats['raw_articles'].get('error', 0) / max(total_articles, 1)) * 100
        fts_coverage = (stats['stage7']['fts_indexed'] / max(stats['stage6']['total_chunks'], 1)) * 100

        # Create analysis prompt
        analysis_prompt = f"""
–¢—ã - –∞–Ω–∞–ª–∏—Ç–∏–∫ RSS –Ω–æ–≤–æ—Å—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–∞–±–æ—Ç—ã —Å–∏—Å—Ç–µ–º—ã –∑–∞ {period_hours} —á–∞—Å–æ–≤ –∏ –¥–∞–π –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.

–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:
- –ê–∫—Ç–∏–≤–Ω—ã—Ö —Ñ–∏–¥–æ–≤: {stats['feeds']['active']}/{stats['feeds']['total']}
- –í—Å–µ–≥–æ —Å—Ç–∞—Ç–µ–π: {total_articles:,}
- –ù–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π –∑–∞ –ø–µ—Ä–∏–æ–¥: {period_total}
- –£—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {stats['raw_articles'].get('stored', 0)} ({success_rate:.1f}%)
- –û—à–∏–±–æ–∫: {stats['raw_articles'].get('error', 0)} ({error_rate:.1f}%)
- –í –æ—á–µ—Ä–µ–¥–∏: {stats['raw_articles'].get('pending', 0)}
- –ì–æ—Ç–æ–≤–æ –∫ —á–∞–Ω–∫–∏–Ω–≥—É: {stats['stage6']['ready_for_chunking']}
- –ó–∞–≤–µ—Ä—à–µ–Ω–æ —á–∞–Ω–∫–æ–≤: {stats['stage6']['chunking_completed']}
- –í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤: {stats['stage6']['total_chunks']}
- FTS –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è: {stats['stage7']['fts_indexed']}/{stats['stage6']['total_chunks']} ({fts_coverage:.1f}%)
- Embeddings: {stats['stage7']['embeddings_stored']}

–î–∞–π –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è):
1. –û–±—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã
2. –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏–ª–∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è
3. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é

–û—Ç–≤–µ—á–∞–π –∫–æ—Ä–æ—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –∏—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏.
"""

        client = AsyncOpenAI(api_key=api_key)

        # GPT-5 –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Responses API
        system_prompt = "–¢—ã - –æ–ø—ã—Ç–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ IT-—Å–∏—Å—Ç–µ–º, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ RSS –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä–∞—Ö –∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –Ω–æ–≤–æ—Å—Ç–µ–π."

        response = await client.responses.create(
            model="gpt-5",
            instructions=system_prompt,
            input=analysis_prompt,
            max_output_tokens=500
        )

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ Responses API —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –ø–∞—Ä—Å–∏–Ω–≥–æ–º
        logger.info(f"GPT-5 response type: {type(response)}")
        logger.info(f"GPT-5 response attributes: {dir(response)}")

        analysis = None

        # –ú–µ—Ç–æ–¥ 1: –ü—Ä—è–º–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ output_text
        if hasattr(response, "output_text") and response.output_text:
            analysis = response.output_text.strip()
            logger.info("GPT-5 analysis extracted via output_text")

        # –ú–µ—Ç–æ–¥ 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ output[].content[].text
        elif hasattr(response, "output") and response.output:
            try:
                parts = []
                for item in response.output:
                    if hasattr(item, "content") and item.content:
                        for content in item.content:
                            if hasattr(content, "text") and content.text:
                                parts.append(content.text)
                if parts:
                    analysis = "\n".join(parts).strip()
                    logger.info("GPT-5 analysis extracted via output[].content[].text")
            except Exception as e:
                logger.warning(f"Failed to extract via output structure: {e}")

        # –ú–µ—Ç–æ–¥ 3: –ü–æ–ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –∏–∑ –ª—é–±–æ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø–æ–ª—è
        if not analysis:
            try:
                response_dict = response.model_dump() if hasattr(response, 'model_dump') else vars(response)
                logger.info(f"GPT-5 response structure: {response_dict}")

                # –ü–æ–∏—Å–∫ –ª—é–±–æ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –≤ –æ—Ç–≤–µ—Ç–µ
                def extract_text_recursive(obj, path=""):
                    texts = []
                    if isinstance(obj, str) and len(obj) > 20:  # –í–µ—Ä–æ—è—Ç–Ω–æ, —ç—Ç–æ –∞–Ω–∞–ª–∏–∑
                        texts.append(obj)
                    elif isinstance(obj, dict):
                        for key, value in obj.items():
                            texts.extend(extract_text_recursive(value, f"{path}.{key}"))
                    elif isinstance(obj, list):
                        for i, value in enumerate(obj):
                            texts.extend(extract_text_recursive(value, f"{path}[{i}]"))
                    return texts

                possible_texts = extract_text_recursive(response_dict)
                if possible_texts:
                    analysis = possible_texts[0].strip()  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                    logger.info(f"GPT-5 analysis extracted recursively: {len(analysis)} chars")

            except Exception as e:
                logger.warning(f"Failed recursive text extraction: {e}")

        if not analysis:
            logger.error("All GPT-5 text extraction methods failed")
            analysis = "–ê–Ω–∞–ª–∏–∑ –ø–æ–ª—É—á–µ–Ω –æ—Ç GPT-5, –Ω–æ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞"

        return f"ü§ñ **GPT-5 –ê–Ω–∞–ª–∏–∑:**\n{analysis}"

    except Exception as e:
        logger.error(f"GPT-5 analysis failed: {e}")
        return f"‚ö†Ô∏è *GPT –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω:* {str(e)[:100]}"


def send_telegram_report(report: str, format: str = "html") -> None:
    """Send report to Telegram"""

    bot_token = os.getenv('TELEGRAM_BOT_TOKEN')
    chat_id = os.getenv('TELEGRAM_CHAT_ID')

    if not bot_token or not chat_id:
        raise ValueError("TELEGRAM_BOT_TOKEN and TELEGRAM_CHAT_ID must be set")

    url = f"https://api.telegram.org/bot{bot_token}/sendMessage"

    # Prepare payload
    payload = {
        'chat_id': chat_id,
        'text': report,
        'parse_mode': 'HTML' if format == 'html' else 'Markdown',
        'disable_web_page_preview': True
    }

    # Truncate if too long (Telegram limit is 4096 chars)
    if len(report) > 4000:
        report = report[:3900] + "\n\n... (truncated)"
        payload['text'] = report

    # Send request
    response = requests.post(url, json=payload, timeout=30)

    if response.status_code != 200:
        raise Exception(f"Telegram API error: {response.status_code} - {response.text}")

    result = response.json()
    if not result.get('ok'):
        raise Exception(f"Telegram API error: {result.get('description', 'Unknown error')}")

    logger.info("Report sent to Telegram successfully")


async def send_enhanced_telegram_report(client, period_hours: int = 8) -> None:
    """Generate and send enhanced report with GPT analysis to Telegram"""

    try:
        # Generate enhanced report with GPT analysis (HTML-safe)
        report = await generate_enhanced_telegram_report(client, period_hours)

        # Send to Telegram as HTML
        send_telegram_report(report, format="html")

        logger.info("Enhanced report with GPT analysis sent to Telegram successfully")

    except Exception as e:
        logger.error(f"Failed to send enhanced Telegram report: {e}")
        raise
