#!/usr/bin/env python3
"""Simple trace of /analyze command with actual execution"""

import os
import sys
import asyncio
import psycopg2
sys.path.insert(0, os.path.dirname(__file__))

print("=" * 80)
print("–¢–†–ï–ô–°–ò–ù–ì –ö–û–ú–ê–ù–î–´ /analyze trump")
print("=" * 80)

# ============================================================================
# –®–ê–ì 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
# ============================================================================
print("\nüíæ –®–ê–ì 1: –ü–†–û–í–ï–†–ö–ê –ë–ê–ó–´ –î–ê–ù–ù–´–•")
print("-" * 80)

dsn = os.getenv('PG_DSN')
conn = psycopg2.connect(dsn)
cur = conn.cursor()

print("\nüìã –¢–∞–±–ª–∏—Ü–∞: article_chunks")

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
cur.execute("""
    SELECT column_name, data_type
    FROM information_schema.columns
    WHERE table_name = 'article_chunks'
      AND column_name IN ('id', 'article_id', 'text', 'url', 'title_norm',
                          'source_domain', 'published_at', 'embedding_vector')
    ORDER BY ordinal_position
""")
columns = cur.fetchall()

print("–ö–ª—é—á–µ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏:")
for col_name, col_type in columns:
    print(f"  ‚úÖ {col_name}: {col_type}")

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö
print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö:")

cur.execute("SELECT COUNT(*) FROM article_chunks WHERE embedding_vector IS NOT NULL")
total = cur.fetchone()[0]
print(f"  –í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏: {total:,}")

cur.execute("""
    SELECT COUNT(*) FROM article_chunks
    WHERE embedding_vector IS NOT NULL
      AND published_at >= NOW() - INTERVAL '24 hours'
""")
recent_24h = cur.fetchone()[0]
print(f"  –ß–∞–Ω–∫–æ–≤ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞: {recent_24h:,}")

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω–¥–µ–∫—Å—ã
cur.execute("""
    SELECT indexname FROM pg_indexes
    WHERE tablename = 'article_chunks' AND indexname LIKE '%embedding%'
""")
indexes = cur.fetchall()

print("\nüîë –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤:")
for (idx_name,) in indexes:
    print(f"  ‚úÖ {idx_name}")

# ============================================================================
# –®–ê–ì 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
# ============================================================================
print("\n\nüß† –®–ê–ì 2: –ì–ï–ù–ï–†–ê–¶–ò–Ø –≠–ú–ë–ï–î–î–ò–ù–ì–ê –ó–ê–ü–†–û–°–ê")
print("-" * 80)

async def generate_embedding():
    from openai_embedding_generator import OpenAIEmbeddingGenerator

    gen = OpenAIEmbeddingGenerator()
    print("–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: 'trump'")

    embeddings = await gen.generate_embeddings(["trump"])

    if not embeddings or not embeddings[0]:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥")
        return None

    query_embedding = embeddings[0]
    print(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω —ç–º–±–µ–¥–¥–∏–Ω–≥: {len(query_embedding)} –∏–∑–º–µ—Ä–µ–Ω–∏–π")

    return query_embedding

query_embedding = asyncio.run(generate_embedding())

if not query_embedding:
    exit(1)

# ============================================================================
# –®–ê–ì 3: –ü—Ä—è–º–æ–π SQL –∑–∞–ø—Ä–æ—Å –∫ –±–∞–∑–µ
# ============================================================================
print("\n\nüîç –®–ê–ì 3: –ü–†–Ø–ú–û–ô SQL –ó–ê–ü–†–û–° –ö –ë–ê–ó–ï")
print("-" * 80)

vector_str = '[' + ','.join(str(x) for x in query_embedding) + ']'

print(f"SQL –∑–∞–ø—Ä–æ—Å:")
print(f"  SELECT ... FROM article_chunks")
print(f"  WHERE embedding_vector IS NOT NULL")
print(f"    AND published_at >= NOW() - INTERVAL '24 hours'")
print(f"  ORDER BY embedding_vector <=> [query_vector]")
print(f"  LIMIT 10")

cur.execute("""
    SELECT
        ac.id, ac.article_id, ac.title_norm, ac.source_domain,
        ac.published_at,
        1 - (ac.embedding_vector <=> %s::vector) AS similarity
    FROM article_chunks ac
    WHERE ac.embedding_vector IS NOT NULL
      AND ac.published_at >= NOW() - INTERVAL '24 hours'
    ORDER BY ac.embedding_vector <=> %s::vector
    LIMIT 10
""", (vector_str, vector_str))

direct_results = cur.fetchall()

print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä—è–º–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞: {len(direct_results)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

if direct_results:
    print("\n–¢–æ–ø-5 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
    for i, (chunk_id, article_id, title, domain, pub_at, sim) in enumerate(direct_results[:5], 1):
        print(f"  {i}. [{sim:.3f}] {title[:60]}...")
        print(f"     {domain} | {pub_at}")
else:
    print("‚ùå –ü—Ä—è–º–æ–π SQL –∑–∞–ø—Ä–æ—Å –≤–µ—Ä–Ω—É–ª 0 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

conn.close()

# ============================================================================
# –®–ê–ì 4: –ß–µ—Ä–µ–∑ ProductionDBClient.search_with_time_filter
# ============================================================================
print("\n\nüì¶ –®–ê–ì 4: –ß–ï–†–ï–ó ProductionDBClient.search_with_time_filter")
print("-" * 80)

async def test_db_client():
    from database.production_db_client import ProductionDBClient

    db = ProductionDBClient()
    print("–í—ã–∑—ã–≤–∞–µ–º: db.search_with_time_filter(query='trump', hours=24, limit=10)")

    results = await db.search_with_time_filter(
        query="trump",
        query_embedding=query_embedding,
        hours=24,
        limit=10,
        filters=None
    )

    print(f"‚úÖ ProductionDBClient –≤–µ—Ä–Ω—É–ª: {len(results)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

    if results:
        print("\n–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:")
        for i, doc in enumerate(results[:3], 1):
            title = doc.get('title_norm', 'No title')[:60]
            sim = doc.get('similarity', 0)
            print(f"  {i}. [{sim:.3f}] {title}...")
    else:
        print("‚ùå ProductionDBClient –≤–µ—Ä–Ω—É–ª 0 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

    return results

db_results = asyncio.run(test_db_client())

# ============================================================================
# –®–ê–ì 5: –ß–µ—Ä–µ–∑ RankingAPI.retrieve_for_analysis
# ============================================================================
print("\n\nüéØ –®–ê–ì 5: –ß–ï–†–ï–ó RankingAPI.retrieve_for_analysis")
print("-" * 80)

async def test_ranking_api():
    from ranking_api import RankingAPI

    api = RankingAPI()
    print("–í—ã–∑—ã–≤–∞–µ–º: api.retrieve_for_analysis(query='trump', window='24h', k_final=5)")

    try:
        results = await api.retrieve_for_analysis(
            query="trump",
            window="24h",
            k_final=5
        )

        print(f"‚úÖ RankingAPI –≤–µ—Ä–Ω—É–ª: {len(results)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

        if results:
            print("\n–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (–ø–æ—Å–ª–µ —Å–∫–æ—Ä–∏–Ω–≥–∞ –∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏):")
            for i, doc in enumerate(results[:3], 1):
                title = doc.get('title_norm', 'No title')[:60]
                score = doc.get('final_score', doc.get('similarity', 0))
                print(f"  {i}. [{score:.3f}] {title}...")
        else:
            print("‚ùå RankingAPI –≤–µ—Ä–Ω—É–ª 0 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

        return results

    except Exception as e:
        print(f"‚ùå RankingAPI –≤—ã–±—Ä–æ—Å–∏–ª –æ—à–∏–±–∫—É: {e}")
        import traceback
        traceback.print_exc()
        return []

ranking_results = asyncio.run(test_ranking_api())

# ============================================================================
# –®–ê–ì 6: –ß–µ—Ä–µ–∑ RetrievalClient (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ orchestrator)
# ============================================================================
print("\n\nüîÑ –®–ê–ì 6: –ß–ï–†–ï–ó RetrievalClient (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–æ–º)")
print("-" * 80)

async def test_retrieval_client():
    from core.rag.retrieval_client import get_retrieval_client

    client = get_retrieval_client()
    print("–í—ã–∑—ã–≤–∞–µ–º: client.retrieve(query='trump', window='24h', k_final=5)")

    try:
        results = await client.retrieve(
            query="trump",
            window="24h",
            lang="auto",
            sources=None,
            k_final=5,
            use_rerank=False
        )

        print(f"‚úÖ RetrievalClient –≤–µ—Ä–Ω—É–ª: {len(results)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

        if results:
            print("\n–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:")
            for i, doc in enumerate(results[:3], 1):
                title = doc.get('title_norm', 'No title')[:60]
                score = doc.get('final_score', doc.get('similarity', 0))
                print(f"  {i}. [{score:.3f}] {title}...")
        else:
            print("‚ùå RetrievalClient –≤–µ—Ä–Ω—É–ª 0 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

        return results

    except Exception as e:
        print(f"‚ùå RetrievalClient –≤—ã–±—Ä–æ—Å–∏–ª –æ—à–∏–±–∫—É: {e}")
        import traceback
        traceback.print_exc()
        return []

retrieval_results = asyncio.run(test_retrieval_client())

# ============================================================================
# –ò–¢–û–ì–û–í–´–ô –ê–ù–ê–õ–ò–ó
# ============================================================================
print("\n\n" + "=" * 80)
print("üìä –ò–¢–û–ì–û–í–´–ô –ê–ù–ê–õ–ò–ó")
print("=" * 80)

print(f"""
‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö:
   - –¢–∞–±–ª–∏—Ü–∞ article_chunks: —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
   - –ö–æ–ª–æ–Ω–∫–∏ (id, embedding_vector, published_at, title_norm): –µ—Å—Ç—å
   - –ò–Ω–¥–µ–∫—Å—ã –Ω–∞ embedding_vector: –µ—Å—Ç—å
   - –í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏: {total:,}
   - –ß–∞–Ω–∫–æ–≤ –∑–∞ 24 —á–∞—Å–∞: {recent_24h:,}

‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥:
   - –ú–æ–¥–µ–ª—å: OpenAI text-embedding-3-large
   - –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {len(query_embedding)}
   - –ó–∞–ø—Ä–æ—Å: "trump"

üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–æ–≤:
   1. –ü—Ä—è–º–æ–π SQL –∑–∞–ø—Ä–æ—Å: {len(direct_results)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
   2. ProductionDBClient: {len(db_results)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
   3. RankingAPI: {len(ranking_results)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
   4. RetrievalClient: {len(retrieval_results)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
""")

if len(direct_results) > 0 and len(ranking_results) == 0:
    print("‚ö†Ô∏è –ü–†–û–ë–õ–ï–ú–ê –ù–ê–ô–î–ï–ù–ê:")
    print("   –ü—Ä—è–º–æ–π SQL –∑–∞–ø—Ä–æ—Å –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã,")
    print("   –Ω–æ RankingAPI –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 0 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.")
    print("   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –≤—ã—à–µ –Ω–∞ –æ—à–∏–±–∫–∏ –≤ —Å–∫–æ—Ä–∏–Ω–≥–µ –∏–ª–∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏.")
elif len(direct_results) == 0:
    print("‚ö†Ô∏è –ü–†–û–ë–õ–ï–ú–ê:")
    print("   –î–∞–∂–µ –ø—Ä—è–º–æ–π SQL –∑–∞–ø—Ä–æ—Å –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã.")
    print("   –ü—Ä–æ–±–ª–µ–º–∞ –≤ –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ SQL –∑–∞–ø—Ä–æ—Å–µ.")
elif len(ranking_results) > 0 and len(retrieval_results) == 0:
    print("‚ö†Ô∏è –ü–†–û–ë–õ–ï–ú–ê:")
    print("   RankingAPI —Ä–∞–±–æ—Ç–∞–µ—Ç, –Ω–æ RetrievalClient –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 0.")
    print("   –ü—Ä–æ–±–ª–µ–º–∞ –≤ RetrievalClient –∏–ª–∏ –µ–≥–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏.")
elif len(retrieval_results) > 0:
    print("‚úÖ –í–°–ï –†–ê–ë–û–¢–ê–ï–¢ –ö–û–†–†–ï–ö–¢–ù–û!")
    print("   Retrieval pipeline –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.")
    print("   /analyze –¥–æ–ª–∂–Ω–∞ —Ä–∞–±–æ—Ç–∞—Ç—å –≤ –±–æ—Ç–µ.")

print("\n" + "=" * 80)
