# ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° /ask - ĞŸĞ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹

**Ğ”Ğ°Ñ‚Ğ°:** 2025-10-05
**Ğ’ĞµÑ€ÑĞ¸Ñ:** Phase 3 Agentic RAG
**ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°:** Multi-agent iterative retrieval with self-correction

---

## ğŸ“‹ Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ°Ğ½Ğ¸Ğµ

1. [ĞĞ±Ñ‰Ğ¸Ğ¹ Ğ¾Ğ±Ğ·Ğ¾Ñ€](#Ğ¾Ğ±Ñ‰Ğ¸Ğ¹-Ğ¾Ğ±Ğ·Ğ¾Ñ€)
2. [ĞŸĞ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ](#Ğ¿Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ğ¹-Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ)
3. [ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ²](#Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°-ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ²)
4. [Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¾Ñ‚Ğ¾Ğº Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…](#Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹-Ğ¿Ğ¾Ñ‚Ğ¾Ğº-Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…)
5. [ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹](#Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹-Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹)
6. [ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº](#Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°-Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº)

---

## ĞĞ±Ñ‰Ğ¸Ğ¹ Ğ¾Ğ±Ğ·Ğ¾Ñ€

### Ğ§Ñ‚Ğ¾ Ğ´ĞµĞ»Ğ°ĞµÑ‚ /ask?

ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° `/ask` - ÑÑ‚Ğ¾ **Agentic RAG** (Retrieval-Augmented Generation) ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ:

- ğŸ“š **Ğ˜Ñ‰ĞµÑ‚** Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ğµ ÑÑ‚Ğ°Ñ‚ÑŒĞ¸ Ğ² Ğ±Ğ°Ğ·Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… (semantic + keyword search)
- ğŸ¤– **ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚** Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ğµ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ LLM
- ğŸ”„ **Ğ˜Ñ‚ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚** Ğ¾Ñ‚Ğ²ĞµÑ‚ Ñ‡ĞµÑ€ĞµĞ· Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ñ€Ğ°ÑƒĞ½Ğ´Ğ¾Ğ² (depth=1/2/3)
- âœ… **ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ ÑĞµĞ±Ñ** (self-correction Ğ½Ğ° depth=3)
- ğŸ“Š **Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚** Ğ¾Ñ‚Ğ²ĞµÑ‚ Ñ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ°Ğ¼Ğ¸ Ğ¸ Ğ´Ğ°Ñ‚Ğ°Ğ¼Ğ¸

### ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:

```
ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ â†’ Telegram:
/ask What are the key arguments for and against TikTok divestiture?

Ğ‘Ğ¾Ñ‚ â†’ ĞÑ‚Ğ²ĞµÑ‚:
ğŸ§  Agentic RAG (depth=3): What are the key arguments...

**Arguments For Divestiture:**
â€¢ National security concerns...
â€¢ Bipartisan support...

**Arguments Against:**
â€¢ First Amendment concerns...
â€¢ Economic impact...

ğŸ“Š Sources:
1. Trump's TikTok Deal... (Today, Oct 5)
2. Democrats' shutdown... (BBC, Oct 2)
```

---

## ĞŸĞ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ

### Ğ¨Ğ°Ğ³ 1: ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ğ¾Ñ‚ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ (Telegram)

**Ğ¤Ğ°Ğ¹Ğ»:** [bot_service/advanced_bot.py:1268](bot_service/advanced_bot.py#L1268)

```python
# ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚:
/ask What are the key arguments for TikTok divestiture? --depth=3

# Telegram bot Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñƒ
async def handle_ask_deep_command(self, chat_id: str, user_id: str, args: List[str]):
    # 1. ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ Ğ°Ñ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²
    depth = 3  # Ğ¸Ğ· --depth=3
    query = "What are the key arguments for TikTok divestiture?"

    # 2. ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
    await self._send_message(chat_id, "ğŸ§  Agentic RAG (depth=3): What are...")

    # 3. Ğ’Ñ‹Ğ·Ğ¾Ğ² Phase3 Handler
    from services.phase3_handlers import execute_ask_command

    payload = await execute_ask_command(
        query=query,
        depth=depth,
        window="24h",
        lang="auto",
        k_final=5,
        correlation_id=f"ask-{user_id}"
    )
```

**Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ¨Ğ°Ğ³Ğ° 1:**
- âœ… Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ñ€Ğ°ÑĞ¿Ğ°Ñ€ÑĞµĞ½
- âœ… ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ğ» ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğµ
- â­ï¸  ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´ Ğº Phase3Handlers

---

### Ğ¨Ğ°Ğ³ 2: Phase3 Handler Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°

**Ğ¤Ğ°Ğ¹Ğ»:** [services/phase3_handlers.py:28](services/phase3_handlers.py#L28)

```python
class Phase3HandlerService:
    async def handle_ask_command(self, *, query: str, depth: int = 3, ...):
        # 1. Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°
        logger.info(f"[Phase3] /ask | query='{query[:50]}...' depth={depth}")

        # 2. ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ°Ñ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ Context Builder
        args_tokens = [
            'query="What are the key arguments..."',
            'window=24h',
            'lang=auto',
            'k=5',
            'depth=3'
        ]

        # 3. Ğ’Ñ‹Ğ·Ğ¾Ğ² Context Builder
        context, error_payload = await self._build_context(
            raw_command="/ask",
            args_tokens=args_tokens,
            correlation_id=correlation_id,
            lang="auto",
            window="24h",
            k_final=5,
            max_tokens=8000,
            budget_cents=50,
            timeout_s=30
        )

        if error_payload:
            return error_payload  # ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°

        # 4. Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ depth Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚
        context["params"]["depth"] = depth

        # 5. Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ñ‡ĞµÑ€ĞµĞ· Orchestrator
        response_dict = await self.orchestrator.execute(context)

        # 6. Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Telegram
        payload = format_for_telegram(response_dict)

        return payload
```

**Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ¨Ğ°Ğ³Ğ° 2:**
- âœ… ĞÑ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ»ĞµĞ½Ñ‹
- â­ï¸  Ğ’Ñ‹Ğ·Ğ¾Ğ² Context Builder

---

### Ğ¨Ğ°Ğ³ 3: Context Builder - Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°

**Ğ¤Ğ°Ğ¹Ğ»:** [core/context/phase3_context_builder.py:40](core/context/phase3_context_builder.py#L40)

```python
class Phase3ContextBuilder:
    async def build_context(self, raw_input: Dict[str, Any]) -> Dict[str, Any]:
        # 1. Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ²Ñ…Ğ¾Ğ´Ğ°
        if not raw_input.get("raw_command"):
            return self._error_response("VALIDATION_FAILED", ...)

        # 2. ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹ Ğ¸ Ğ°Ñ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²
        command = self._normalize_command("/ask")  # â†’ "ask"
        parsed_args = self._parse_args(args, command)

        # 3. ĞŸĞ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ params
        params = self._build_params(parsed_args, defaults, user_lang)
        # params = {
        #     "query": "What are the key arguments...",
        #     "window": "24h",
        #     "lang": "auto",
        #     "k_final": 5,
        #     "sources": None,
        #     "flags": {"rerank_enabled": True}
        # }

        # 4. ĞŸĞ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ models (Ğ¼Ğ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğº Ğ½ÑƒĞ¶Ğ½Ñ‹Ğ¼ LLM)
        models = self._build_models(command)
        # models = {
        #     "primary": "gpt-5",
        #     "fallback": ["gpt-5-mini", "gpt-3.5-turbo"]
        # }

        # 5. ĞŸĞ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ limits (Ğ±ÑĞ´Ğ¶ĞµÑ‚ Ğ¸ Ñ‚Ğ°Ğ¹Ğ¼Ğ°ÑƒÑ‚Ñ‹)
        limits = self._build_limits(defaults)
        # limits = {
        #     "max_tokens": 8000,
        #     "budget_cents": 50,
        #     "timeout_s": 30
        # }

        # 6. ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§ĞĞ: Retrieval Ñ auto-recovery
        retrieval, recovery_warnings = await self._perform_retrieval_with_recovery(
            params, feature_flags, correlation_id
        )

        if not retrieval["docs"]:
            return self._error_response(
                "NO_DATA",
                "No documents found for query",
                f"Retrieval returned 0 documents after auto-recovery attempts."
            )

        # 7. ĞšĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° k_final Ğ¿Ğ¾Ğ´ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²
        params["k_final"] = len(retrieval["docs"])

        # 8. ĞŸĞ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ telemetry
        telemetry = {
            "correlation_id": correlation_id,
            "version": "phase3-orchestrator"
        }

        # 9. Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚
        context = {
            "command": "ask",
            "params": params,
            "retrieval": retrieval,
            "graph": None,
            "memory": None,
            "models": models,
            "limits": limits,
            "telemetry": telemetry
        }

        return context
```

**Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ¨Ğ°Ğ³Ğ° 3:**
- âœ… ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½
- âœ… 3-5 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ (Ğ¸Ğ»Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞ° NO_DATA)
- â­ï¸  ĞŸĞµÑ€ĞµĞ´Ğ°Ñ‡Ğ° Ğ² Orchestrator

---

### Ğ¨Ğ°Ğ³ 3.1: Retrieval Ñ Auto-Recovery (ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ğ¾Ğ´Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ)

**Ğ¤Ğ°Ğ¹Ğ»:** [core/context/phase3_context_builder.py:348](core/context/phase3_context_builder.py#L348)

Ğ­Ñ‚Ğ¾ **ÑĞ°Ğ¼Ğ°Ñ Ğ²Ğ°Ğ¶Ğ½Ğ°Ñ Ñ‡Ğ°ÑÑ‚ÑŒ** - Ğ¿Ğ¾Ğ¸ÑĞº Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸ĞµĞ¼.

```python
async def _perform_retrieval_with_recovery(self, params, feature_flags, correlation_id):
    warnings = []
    window = params["window"]  # "24h"
    lang = params["lang"]      # "auto"
    sources = params["sources"]  # None
    k_final = params["k_final"]  # 5
    rerank_enabled = params["flags"]["rerank_enabled"]  # True

    # ĞŸĞ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ query
    query = self._build_retrieval_query(params)
    # query = "What are the key arguments for TikTok divestiture?"

    # === ATTEMPT 1: Normal retrieval ===
    docs = await self._retrieve_docs(
        query, window, lang, sources, k_final, rerank_enabled
    )

    if docs:
        return self._build_retrieval_dict(docs, ...), warnings

    # === AUTO-RECOVERY STARTS ===

    # STEP 1: Expand window (24h â†’ 3d â†’ 1w â†’ 2w â†’ 1m â†’ 3m)
    if feature_flags.get("auto_expand_window", True):
        max_attempts = 5
        attempts = 0
        while not docs and attempts < max_attempts:
            new_window = WINDOW_EXPANSION.get(window, window)
            if new_window == window:
                break  # Cannot expand further

            window = new_window
            attempts += 1
            warnings.append(f"expanded window to {window}")

            docs = await self._retrieve_docs(query, window, ...)

            if docs:
                return self._build_retrieval_dict(docs, ...), warnings

    # STEP 2: Relax filters (lang â†’ auto, sources â†’ None)
    if feature_flags.get("relax_filters_on_empty", True):
        lang = "auto"
        sources = None
        warnings.append("relaxed lang to auto, removed source filters")

        docs = await self._retrieve_docs(query, window, ...)

        if docs:
            return self._build_retrieval_dict(docs, ...), warnings

    # STEP 3: Disable rerank and increase k_final
    if feature_flags.get("fallback_rerank_false_on_empty", True):
        rerank_enabled = False
        k_final = 10
        warnings.append("disabled rerank, increased k_final to 10")

        docs = await self._retrieve_docs(query, window, ...)

        if docs:
            return self._build_retrieval_dict(docs, ...), warnings

    # === ALL RECOVERY ATTEMPTS FAILED ===
    return self._build_retrieval_dict([], ...), warnings
```

**Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Auto-Recovery:**
- âœ… ĞŸĞ¾Ğ¿Ñ‹Ñ‚ĞºĞ° 1: ĞĞ±Ñ‹Ñ‡Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº (24h window)
- â­ï¸  ĞŸĞ¾Ğ¿Ñ‹Ñ‚ĞºĞ° 2-6: Ğ Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ğµ Ğ¾ĞºĞ½Ğ° (3d, 1w, 2w, 1m, 3m)
- â­ï¸  ĞŸĞ¾Ğ¿Ñ‹Ñ‚ĞºĞ° 7: Ğ ĞµĞ»Ğ°ĞºÑĞ°Ñ†Ğ¸Ñ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ¾Ğ²
- â­ï¸  ĞŸĞ¾Ğ¿Ñ‹Ñ‚ĞºĞ° 8: ĞÑ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ rerank
- âŒ Ğ•ÑĞ»Ğ¸ Ğ²ÑĞµ failed â†’ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚ Ğ¿ÑƒÑÑ‚Ğ¾Ğ³Ğ¾ ÑĞ¿Ğ¸ÑĞºĞ°

---

### Ğ¨Ğ°Ğ³ 3.2: _retrieve_docs - Ğ¤Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº Ğ² Ğ‘Ğ”

**Ğ¤Ğ°Ğ¹Ğ»:** [core/context/phase3_context_builder.py:455](core/context/phase3_context_builder.py#L455)

```python
async def _retrieve_docs(self, query: str, window: str, lang: str, ...):
    try:
        # 1. Ğ’Ñ‹Ğ·Ğ¾Ğ² RetrievalClient
        docs = await self.retrieval_client.retrieve(
            query=query,
            window=window,
            lang=lang,
            sources=sources,
            k_final=k_final,
            use_rerank=rerank_enabled
        )

        # 2. ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° Ğ¸ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²
        cleaned_docs = []
        for doc in docs:
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° required fields
            if not doc.get("title"):
                continue

            # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ date
            date = doc.get("date")
            if not date or not self._is_valid_date(date):
                date = datetime.utcnow().strftime("%Y-%m-%d")

            # Trim snippet
            snippet = doc.get("snippet", "")[:240]

            cleaned_docs.append({
                "article_id": doc.get("article_id"),
                "title": doc.get("title", ""),
                "url": doc.get("url"),
                "date": date,
                "lang": doc_lang,
                "score": doc.get("score", 0.0),
                "snippet": snippet
            })

        return cleaned_docs

    except Exception as e:
        logger.error(f"Retrieval failed: {e}")
        return []
```

**Ğ’Ğ½ÑƒÑ‚Ñ€Ğ¸ retrieval_client.retrieve():**

**Ğ¤Ğ°Ğ¹Ğ»:** [core/rag/retrieval_client.py:76](core/rag/retrieval_client.py#L76)

```python
async def retrieve(self, query, window, lang, sources, k_final, use_rerank):
    # 1. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ĞºÑÑˆĞ°
    cache_key = self._build_cache_key(query, window, ...)
    cached = self._get_from_cache(cache_key)
    if cached:
        return cached

    # 2. ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ RankingAPI
    api = self._get_ranking_api()

    # 3. Ğ’Ñ‹Ğ·Ğ¾Ğ² ranking_api.retrieve_for_analysis()
    results = await api.retrieve_for_analysis(
        query=query,
        window=window,
        lang=lang,
        sources=sources,
        k_final=k_final,
        use_rerank=use_rerank
    )

    # 4. ĞšÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
    if results:
        self._set_cache(cache_key, results)

    return results
```

**Ğ’Ğ½ÑƒÑ‚Ñ€Ğ¸ ranking_api.retrieve_for_analysis():**

**Ğ¤Ğ°Ğ¹Ğ»:** [ranking_api.py:367](ranking_api.py#L367)

```python
async def retrieve_for_analysis(self, query, window, lang, sources, k_final, use_rerank):
    # 1. ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ time window
    window_hours = {"24h": 24, "3d": 72, "1w": 168, ...}.get(window, 24)

    # 2. ĞŸĞ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ filters
    filters = {}
    if sources:
        filters['sources'] = sources
    if lang and lang != 'auto':
        filters['lang'] = lang

    # 3. Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ query embedding
    query_normalized = self._normalize_query(query)
    query_embeddings = await self.embedding_generator.generate_embeddings([query_normalized])

    if not query_embeddings or not query_embeddings[0]:
        logger.warning("Failed to generate query embedding")
        return []

    query_embedding = query_embeddings[0]

    # 4. Hybrid search (semantic + FTS)
    results = await self.db.search_with_time_filter(
        query=query_normalized,
        query_embedding=query_embedding,
        hours=window_hours,
        limit=k_final * 2,  # Get more candidates
        filters=filters
    )

    # 5. Scoring
    if results:
        scored_results = self.scorer.score_and_rank(results, query)

        # 6. Deduplication (FIXED LSH)
        if len(scored_results) > 1:
            deduplicated = self.dedup_engine.canonicalize_articles(scored_results)
        else:
            deduplicated = scored_results

        # 7. Return top k_final
        return deduplicated[:k_final]

    return []
```

**Ğ’Ğ½ÑƒÑ‚Ñ€Ğ¸ db.search_with_time_filter():**

**Ğ¤Ğ°Ğ¹Ğ»:** [database/production_db_client.py:622](database/production_db_client.py#L622)

```python
async def search_with_time_filter(self, query, query_embedding, hours, limit, filters):
    # 1. ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ñ embedding Ğ² pgvector Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚
    vector_str = '[' + ','.join(str(x) for x in query_embedding) + ']'

    # 2. ĞŸĞ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ WHERE clauses
    where_clauses = ["ac.embedding_vector IS NOT NULL"]
    where_clauses.append("ac.published_at >= NOW() - (%s || ' hours')::interval")
    params = [vector_str, hours]

    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ source filter
    if filters and filters.get('sources'):
        placeholders = ','.join(['%s'] * len(filters['sources']))
        where_clauses.append(f"ac.source_domain IN ({placeholders})")
        params.extend(filters['sources'])

    where_sql = " AND ".join(where_clauses)

    # 3. SQL Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ñ pgvector ĞºĞ¾ÑĞ¸Ğ½ÑƒÑĞ½Ñ‹Ğ¼ Ñ€Ğ°ÑÑÑ‚Ğ¾ÑĞ½Ğ¸ĞµĞ¼
    query_sql = f"""
        SELECT
            ac.id, ac.article_id, ac.chunk_index, ac.text,
            ac.url, ac.title_norm, ac.source_domain, ac.published_at,
            1 - (ac.embedding_vector <=> %s::vector) AS similarity
        FROM article_chunks ac
        WHERE {where_sql}
        ORDER BY ac.embedding_vector <=> %s::vector
        LIMIT %s
    """

    params.extend([vector_str, limit])

    # 4. Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°
    cur.execute(query_sql, params)

    # 5. Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
    results = []
    for row in cur.fetchall():
        results.append({
            'id': row[0],
            'article_id': row[1],
            'text': row[3],
            'url': row[4],
            'title_norm': row[5],
            'source_domain': row[6],
            'published_at': str(row[7]),
            'similarity': float(row[8]),
            'semantic_score': float(row[8]),
            'fts_score': 0.5
        })

    return results
```

**Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ² Ğ‘Ğ”:**
```python
[
    {
        'article_id': 32807,
        'title_norm': "Government Shutdown Enters 5th Day...",
        'text': "Trump's TikTok Deal Gives Control of Platform...",
        'url': "https://www.today.com/video/...",
        'published_at': "2025-10-05 12:42:36+00:00",
        'similarity': 0.581,
        'semantic_score': 0.581,
        'fts_score': 0.5
    },
    {
        'article_id': 32717,
        'title_norm': "Americast - Will the Democrats' shutdown gamble...",
        'text': "Donald Trump has reached a deal to transfer TikTok...",
        'url': "https://www.bbc.co.uk/sounds/play/...",
        'published_at': "2025-10-02 18:15:00+00:00",
        'similarity': 0.603,
        ...
    },
    {
        'article_id': 30440,
        'title_norm': "Is TikTok about to go full Maga? â€“ podcast...",
        'text': "Emily Baker-White on the deal to transfer TikTok's US operations...",
        'url': "https://www.theguardian.com/news/audio/...",
        'published_at': "2025-10-03 02:00:21+00:00",
        'similarity': 0.569,
        ...
    }
]
```

---

### Ğ¨Ğ°Ğ³ 4: Phase3 Orchestrator - Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹

**Ğ¤Ğ°Ğ¹Ğ»:** [core/orchestrator/phase3_orchestrator_new.py:70](core/orchestrator/phase3_orchestrator_new.py#L70)

```python
class Phase3Orchestrator:
    async def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        command = context.get("command", "")
        correlation_id = context.get("telemetry", {}).get("correlation_id")

        logger.info(f"[{correlation_id}] Executing Phase 3 command: {command}")

        try:
            # 1. ĞœĞ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹
            if command.startswith("/ask"):
                response = await self._handle_agentic(context)
            elif command.startswith("/events"):
                response = await self._handle_events(context)
            elif command.startswith("/graph"):
                response = await self._handle_graph(context)
            ...

            # 2. Ğ¡Ğ°Ğ½Ğ¸Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ evidence (PII masking, domain checks)
            if hasattr(response, 'evidence'):
                response.evidence = PIIMasker.sanitize_evidence(response.evidence)

            # 3. Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· policy layer
            self.validator.validate_response(response)

            logger.info(f"[{correlation_id}] Command completed successfully")
            return response.model_dump()

        except Exception as e:
            logger.error(f"[{correlation_id}] Command failed: {e}")
            return self._build_error_response(str(e), context)
```

---

### Ğ¨Ğ°Ğ³ 4.1: Agentic RAG Agent - Ğ˜Ñ‚ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·

**Ğ¤Ğ°Ğ¹Ğ»:** [core/orchestrator/phase3_orchestrator_new.py:120](core/orchestrator/phase3_orchestrator_new.py#L120)

```python
async def _handle_agentic(self, context: Dict[str, Any]):
    # 1. Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°
    docs = context.get("retrieval", {}).get("docs", [])
    params = context.get("params", {})
    query = params.get("query") or "primary question"
    lang = params.get("lang", "en")
    window = context.get("retrieval", {}).get("window", "24h")

    # 2. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ budget manager
    limits = context.get("limits", {})
    budget = create_budget_manager(
        max_tokens=limits.get("max_tokens", 8000),
        budget_cents=limits.get("budget_cents", 50),
        timeout_s=limits.get("timeout_s", 30)
    )

    # 3. Degradation ĞµÑĞ»Ğ¸ Ğ±ÑĞ´Ğ¶ĞµÑ‚ Ğ¿Ñ€ĞµĞ²Ñ‹ÑˆĞµĞ½
    depth = params.get("depth", 3)
    if budget.should_degrade():
        degraded = budget.get_degraded_params("/ask", {"depth": depth})
        depth = degraded.get("depth", 1)

    # 4. Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Agentic RAG
    agentic_result, all_docs = await self.agentic_rag_agent.execute(
        query=query,
        initial_docs=docs,
        depth=depth,
        retrieval_fn=self._create_retrieval_fn(window, lang),
        budget_manager=budget,
        lang=lang,
        window=window
    )

    # 5. Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°
    insights = [
        Insight(
            text=agentic_result.answer,
            confidence=agentic_result.confidence,
            rationale=agentic_result.reasoning,
            strength="high" if agentic_result.confidence > 0.8 else "medium"
        )
    ]

    # 6. ĞŸĞ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ evidence Ğ¸Ğ· Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²
    evidence = self._build_evidence_from_docs(all_docs)

    # 7. ĞŸĞ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ğ³Ğ¾ response
    return build_base_response(
        command="ask",
        insights=insights,
        evidence=evidence,
        lang=lang,
        meta=Meta(
            query=query,
            window=window,
            total_docs=len(all_docs),
            retrieval_depth=depth,
            model_used=agentic_result.model_used,
            correlation_id=context.get("telemetry", {}).get("correlation_id")
        )
    )
```

**Ğ’Ğ½ÑƒÑ‚Ñ€Ğ¸ agentic_rag_agent.execute():**

**Ğ¤Ğ°Ğ¹Ğ»:** [core/agents/agentic_rag.py](core/agents/agentic_rag.py)

```python
async def execute(self, query, initial_docs, depth, retrieval_fn, budget_manager, lang, window):
    iterations = []
    current_docs = initial_docs
    all_docs = list(initial_docs)

    # === ITERATION 1 ===
    answer_1, reasoning_1, needs_more_1 = await self._analyze_and_answer(
        query=query,
        docs=current_docs,
        iteration=1,
        budget_manager=budget_manager,
        lang=lang
    )

    iterations.append({
        "iteration": 1,
        "answer": answer_1,
        "reasoning": reasoning_1,
        "needs_more_info": needs_more_1,
        "docs_used": len(current_docs)
    })

    if depth == 1:
        # Quick answer mode
        return self._build_result(answer_1, reasoning_1, iterations, all_docs)

    # === ITERATION 2 ===
    if needs_more_1:
        # Ğ—Ğ°Ğ¿Ñ€Ğ¾ÑĞ¸Ñ‚ÑŒ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ‹
        refined_query = await self._refine_query(query, answer_1, reasoning_1)
        new_docs = await retrieval_fn(refined_query, k=3)

        # ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½Ğ¸Ñ‚ÑŒ Ñ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğ¼Ğ¸
        current_docs = self._merge_docs(current_docs, new_docs)
        all_docs.extend(new_docs)

    answer_2, reasoning_2, needs_more_2 = await self._analyze_and_answer(
        query=query,
        docs=current_docs,
        iteration=2,
        budget_manager=budget_manager,
        lang=lang
    )

    iterations.append({
        "iteration": 2,
        "answer": answer_2,
        "reasoning": reasoning_2,
        "needs_more_info": needs_more_2,
        "docs_used": len(current_docs)
    })

    if depth == 2:
        # Standard mode
        return self._build_result(answer_2, reasoning_2, iterations, all_docs)

    # === ITERATION 3 (Self-correction) ===
    if needs_more_2:
        refined_query = await self._refine_query(query, answer_2, reasoning_2)
        new_docs = await retrieval_fn(refined_query, k=2)
        current_docs = self._merge_docs(current_docs, new_docs)
        all_docs.extend(new_docs)

    # Self-check: Compare iterations 1 and 2
    consistency_check = await self._check_consistency(answer_1, answer_2)

    if not consistency_check.is_consistent:
        # Re-analyze with all accumulated evidence
        answer_3, reasoning_3, _ = await self._analyze_and_answer(
            query=query,
            docs=current_docs,
            iteration=3,
            budget_manager=budget_manager,
            lang=lang,
            previous_answers=[answer_1, answer_2],
            consistency_issues=consistency_check.issues
        )
    else:
        answer_3 = answer_2
        reasoning_3 = reasoning_2 + " (Consistent with previous iteration)"

    iterations.append({
        "iteration": 3,
        "answer": answer_3,
        "reasoning": reasoning_3,
        "self_corrected": not consistency_check.is_consistent,
        "docs_used": len(current_docs)
    })

    # Deep mode - final answer
    return self._build_result(answer_3, reasoning_3, iterations, all_docs)
```

**Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Agentic RAG:**
```python
{
    "answer": "**Arguments For TikTok Divestiture:**\nâ€¢ National security concerns...\n\n**Arguments Against:**\nâ€¢ First Amendment concerns...",
    "reasoning": "Based on analysis of 5 recent articles...",
    "confidence": 0.85,
    "iterations": [
        {"iteration": 1, "answer": "...", "docs_used": 3},
        {"iteration": 2, "answer": "...", "docs_used": 5},
        {"iteration": 3, "answer": "...", "docs_used": 5, "self_corrected": False}
    ],
    "model_used": "gpt-5",
    "all_docs": [...]
}
```

---

### Ğ¨Ğ°Ğ³ 5: Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Telegram

**Ğ¤Ğ°Ğ¹Ğ»:** [core/ux/formatter.py](core/ux/formatter.py)

```python
def format_for_telegram(response_dict: Dict[str, Any]) -> Dict[str, Any]:
    # 1. Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
    command = response_dict.get("command", "")
    insights = response_dict.get("insights", [])
    evidence = response_dict.get("evidence", [])
    meta = response_dict.get("meta", {})

    # 2. ĞŸĞ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ Ñ‚ĞµĞºÑÑ‚Ğ°
    if command == "ask":
        text = "ğŸ§  **Agentic RAG Result**\n\n"

        # Main answer
        if insights:
            text += insights[0].get("text", "")
            text += "\n\n"

        # Sources
        if evidence:
            text += "ğŸ“Š **Sources:**\n"
            for i, ev in enumerate(evidence[:5], 1):
                title = ev.get("title", "")[:70]
                date = ev.get("date", "")
                url = ev.get("url", "")
                text += f"{i}. [{title}]({url})\n"
                text += f"   {date}\n"

        # Meta info
        if meta:
            text += f"\nğŸ” Window: {meta.get('window', 'N/A')} | "
            text += f"Docs: {meta.get('total_docs', 0)} | "
            text += f"Depth: {meta.get('retrieval_depth', 1)}"

    return {
        "text": text,
        "buttons": None,
        "parse_mode": "Markdown"
    }
```

---

### Ğ¨Ğ°Ğ³ 6: ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ

**Ğ¤Ğ°Ğ¹Ğ»:** [bot_service/advanced_bot.py:1315](bot_service/advanced_bot.py#L1315)

```python
# ĞŸĞ¾ÑĞ»Ğµ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ payload
return await self._send_orchestrator_payload(chat_id, payload)

# _send_orchestrator_payload:
async def _send_orchestrator_payload(self, chat_id: str, payload: Dict[str, Any]):
    text = payload.get("text", "No response")
    buttons = payload.get("buttons")
    parse_mode = payload.get("parse_mode", "Markdown")

    # ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ğ² Telegram
    if buttons:
        await self._send_message_with_buttons(chat_id, text, buttons, parse_mode)
    else:
        await self._send_message(chat_id, text, parse_mode=parse_mode)

    return True
```

**ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚:**

```
ğŸ§  Agentic RAG Result

**Arguments For TikTok Divestiture:**
â€¢ National security concerns about Chinese government access to US user data
â€¢ Bipartisan Congressional support for restrictions
â€¢ Trump administration deal to transfer control to US media moguls

**Arguments Against:**
â€¢ First Amendment concerns about government ban on social media platform
â€¢ Economic impact on millions of content creators and businesses
â€¢ Questions about effectiveness if Chinese algorithm remains

ğŸ“Š Sources:
1. [Trump's TikTok Deal Gives Control of Platform to Media Moguls](https://www.today.com/video/...)
   2025-10-05
2. [Americast - Will the Democrats' shutdown gamble pay off?](https://www.bbc.co.uk/sounds/...)
   2025-10-02
3. [Is TikTok about to go full Maga? â€“ podcast](https://www.theguardian.com/news/audio/...)
   2025-10-03

ğŸ” Window: 24h | Docs: 5 | Depth: 3
```

---

## ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ²

### Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ°Ñ ÑÑ…ĞµĞ¼Ğ°:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          TELEGRAM                               â”‚
â”‚                     User: /ask TikTok?                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AdvancedRSSBot                               â”‚
â”‚           [bot_service/advanced_bot.py]                         â”‚
â”‚                                                                  â”‚
â”‚  â€¢ Parse command and arguments                                  â”‚
â”‚  â€¢ Send "ğŸ§  Processing..." notification                         â”‚
â”‚  â€¢ Call Phase3Handlers                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Phase3HandlerService                           â”‚
â”‚           [services/phase3_handlers.py]                         â”‚
â”‚                                                                  â”‚
â”‚  â€¢ Prepare args tokens                                          â”‚
â”‚  â€¢ Call Phase3ContextBuilder                                    â”‚
â”‚  â€¢ Add depth parameter                                          â”‚
â”‚  â€¢ Execute via Orchestrator                                     â”‚
â”‚  â€¢ Format response for Telegram                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Phase3ContextBuilder                             â”‚
â”‚      [core/context/phase3_context_builder.py]                  â”‚
â”‚                                                                  â”‚
â”‚  Step 1: Validate & parse command                               â”‚
â”‚  Step 2: Build params (query, window, lang, k_final)            â”‚
â”‚  Step 3: Build models routing (gpt-5, fallbacks)               â”‚
â”‚  Step 4: Build limits (tokens, budget, timeout)                 â”‚
â”‚  Step 5: *** RETRIEVAL WITH AUTO-RECOVERY ***                   â”‚
â”‚     â”œâ”€ Normal retrieval (24h)                                   â”‚
â”‚     â”œâ”€ Expand window (3d, 1w, 2w, 1m, 3m)                       â”‚
â”‚     â”œâ”€ Relax filters (lang=auto, sources=None)                  â”‚
â”‚     â””â”€ Disable rerank, increase k                               â”‚
â”‚  Step 6: Validate docs found                                    â”‚
â”‚  Step 7: Build final context                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RetrievalClient                              â”‚
â”‚            [core/rag/retrieval_client.py]                      â”‚
â”‚                                                                  â”‚
â”‚  â€¢ Check cache                                                  â”‚
â”‚  â€¢ Call RankingAPI.retrieve_for_analysis()                      â”‚
â”‚  â€¢ Cache results                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      RankingAPI                                 â”‚
â”‚                 [ranking_api.py]                                â”‚
â”‚                                                                  â”‚
â”‚  Step 1: Parse time window (24h â†’ 24 hours)                     â”‚
â”‚  Step 2: Build filters (sources, lang)                          â”‚
â”‚  Step 3: Generate query embedding (OpenAI/Local)                â”‚
â”‚  Step 4: Search with time filter (hybrid search)                â”‚
â”‚  Step 5: Score and rank results                                 â”‚
â”‚  Step 6: *** DEDUPLICATION (LSH) ***                            â”‚
â”‚  Step 7: Return top k_final                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                ProductionDBClient                               â”‚
â”‚        [database/production_db_client.py]                      â”‚
â”‚                                                                  â”‚
â”‚  *** POSTGRESQL QUERY ***                                       â”‚
â”‚  SELECT ... FROM article_chunks                                 â”‚
â”‚  WHERE embedding_vector IS NOT NULL                             â”‚
â”‚    AND published_at >= NOW() - '24 hours'::interval             â”‚
â”‚  ORDER BY embedding_vector <=> query_vector                     â”‚
â”‚  LIMIT 10                                                       â”‚
â”‚                                                                  â”‚
â”‚  Returns: 3-5 chunks with similarity scores                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                             â”‚
      â†“                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  pgvector   â”‚            â”‚ embeddings   â”‚
â”‚   Index     â”‚            â”‚  (3072-dim)  â”‚
â”‚   (HNSW)    â”‚            â”‚   OpenAI     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Results: [
  {article_id: 32807, similarity: 0.581, text: "Trump's TikTok..."},
  {article_id: 32717, similarity: 0.603, text: "Donald Trump..."},
  {article_id: 30440, similarity: 0.569, text: "Emily Baker..."}
]
                     â”‚
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Phase3Orchestrator                              â”‚
â”‚      [core/orchestrator/phase3_orchestrator_new.py]            â”‚
â”‚                                                                  â”‚
â”‚  â€¢ Route to _handle_agentic()                                   â”‚
â”‚  â€¢ Create budget manager                                        â”‚
â”‚  â€¢ Execute Agentic RAG Agent                                    â”‚
â”‚  â€¢ Sanitize evidence (PII masking)                              â”‚
â”‚  â€¢ Validate response                                            â”‚
â”‚  â€¢ Return formatted response                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  AgenticRAGAgent                                â”‚
â”‚              [core/agents/agentic_rag.py]                      â”‚
â”‚                                                                  â”‚
â”‚  ITERATION 1 (depth >= 1):                                      â”‚
â”‚    â”œâ”€ Analyze initial docs (3-5 chunks)                         â”‚
â”‚    â”œâ”€ Generate answer_1 + reasoning_1                           â”‚
â”‚    â””â”€ Check if needs_more_info                                  â”‚
â”‚                                                                  â”‚
â”‚  ITERATION 2 (depth >= 2):                                      â”‚
â”‚    â”œâ”€ Refine query if needed                                    â”‚
â”‚    â”œâ”€ Retrieve additional docs (2-3 more)                       â”‚
â”‚    â”œâ”€ Analyze all docs (5-8 chunks total)                       â”‚
â”‚    â”œâ”€ Generate answer_2 + reasoning_2                           â”‚
â”‚    â””â”€ Check if needs_more_info                                  â”‚
â”‚                                                                  â”‚
â”‚  ITERATION 3 (depth = 3):                                       â”‚
â”‚    â”œâ”€ Refine query if needed                                    â”‚
â”‚    â”œâ”€ Retrieve final docs if needed                             â”‚
â”‚    â”œâ”€ *** SELF-CORRECTION ***                                   â”‚
â”‚    â”‚   â””â”€ Check consistency(answer_1, answer_2)                 â”‚
â”‚    â”œâ”€ Re-analyze if inconsistent                                â”‚
â”‚    â””â”€ Generate final answer_3 + reasoning_3                     â”‚
â”‚                                                                  â”‚
â”‚  Return:                                                        â”‚
â”‚    â€¢ Final answer (markdown formatted)                          â”‚
â”‚    â€¢ Reasoning chain                                            â”‚
â”‚    â€¢ Confidence score (0.0-1.0)                                 â”‚
â”‚    â€¢ All documents used (5-10 chunks)                           â”‚
â”‚    â€¢ Model used (gpt-5)                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Formatter                                  â”‚
â”‚              [core/ux/formatter.py]                            â”‚
â”‚                                                                  â”‚
â”‚  â€¢ Format insights (answer text)                                â”‚
â”‚  â€¢ Format evidence (sources with dates)                         â”‚
â”‚  â€¢ Add metadata (window, docs count, depth)                     â”‚
â”‚  â€¢ Build Telegram payload (text + markdown)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       TELEGRAM                                  â”‚
â”‚                    User receives:                               â”‚
â”‚                                                                  â”‚
â”‚  ğŸ§  Agentic RAG Result                                          â”‚
â”‚                                                                  â”‚
â”‚  **Arguments For TikTok Divestiture:**                          â”‚
â”‚  â€¢ National security concerns...                                â”‚
â”‚  â€¢ Bipartisan support...                                        â”‚
â”‚                                                                  â”‚
â”‚  **Arguments Against:**                                         â”‚
â”‚  â€¢ First Amendment concerns...                                  â”‚
â”‚  â€¢ Economic impact...                                           â”‚
â”‚                                                                  â”‚
â”‚  ğŸ“Š Sources:                                                    â”‚
â”‚  1. Trump's TikTok Deal... (Oct 5)                              â”‚
â”‚  2. Democrats' shutdown... (Oct 2)                              â”‚
â”‚  3. TikTok full Maga?... (Oct 3)                                â”‚
â”‚                                                                  â”‚
â”‚  ğŸ” Window: 24h | Docs: 5 | Depth: 3                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº

### ĞÑˆĞ¸Ğ±ĞºĞ° 1: No documents found

**ĞšĞ¾Ğ³Ğ´Ğ°:** Retrieval Ğ½Ğµ Ğ½Ğ°Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ´Ğ°Ğ¶Ğµ Ğ¿Ğ¾ÑĞ»Ğµ auto-recovery

**Ğ¡Ğ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ:**
```
âŒ Phase 3 context builder error

No documents found for query
Retrieval returned 0 documents after auto-recovery attempts.
Window=3m, lang=auto, sources=None.
Steps: expanded window to 3d, expanded window to 1w, ..., increased k_final to 10
```

**ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ñ‹:**
- ĞĞµÑ‚ ÑÑ‚Ğ°Ñ‚ĞµĞ¹ Ğ¿Ğ¾ Ñ‚ĞµĞ¼Ğµ Ğ² Ğ±Ğ°Ğ·Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
- Ğ¡Ğ»Ğ¸ÑˆĞºĞ¾Ğ¼ ÑƒĞ·ĞºĞ¸Ğ¹ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ»
- ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ñ embeddings (Ğ½Ğµ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹)
- LSH deduplication Ğ¾ÑˆĞ¸Ğ±ĞºĞ° (FIXED)

**Ğ ĞµÑˆĞµĞ½Ğ¸Ğµ:**
- Auto-recovery Ñ€Ğ°ÑÑˆĞ¸Ñ€ÑĞµÑ‚ Ğ¾ĞºĞ½Ğ¾ Ğ´Ğ¾ 3 Ğ¼ĞµÑÑÑ†ĞµĞ²
- Ğ ĞµĞ»Ğ°ĞºÑĞ¸Ñ€ÑƒĞµÑ‚ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹ (lang, sources)
- ĞÑ‚ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ rerank
- Ğ•ÑĞ»Ğ¸ Ğ²ÑĞµ Ñ€Ğ°Ğ²Ğ½Ğ¾ Ğ¿ÑƒÑÑ‚Ğ¾ â†’ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ error

---

### ĞÑˆĞ¸Ğ±ĞºĞ° 2: LSH duplicate key (FIXED)

**Ğ‘Ñ‹Ğ»Ğ¾:**
```
ValueError: The given key already exists
```

**ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°:** Article ID Ğ²ÑÑ‚Ğ°Ğ²Ğ»ÑĞ»ÑÑ Ğ² LSH Ğ´Ğ²Ğ°Ğ¶Ğ´Ñ‹

**Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾:** [ASK_COMMAND_LSH_FIX.md](ASK_COMMAND_LSH_FIX.md)

---

### ĞÑˆĞ¸Ğ±ĞºĞ° 3: Budget exceeded

**ĞšĞ¾Ğ³Ğ´Ğ°:** LLM Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¿Ñ€ĞµĞ²Ñ‹ÑˆĞ°ÑÑ‚ Ğ±ÑĞ´Ğ¶ĞµÑ‚ (50 Ñ†ĞµĞ½Ñ‚Ğ¾Ğ²)

**Ğ”ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ:**
- Budget manager Ğ´ĞµĞ³Ñ€Ğ°Ğ´Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹
- depth 3 â†’ 2 â†’ 1
- ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°ĞµÑ‚ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñƒ Ñ ÑƒĞ¿Ñ€Ğ¾Ñ‰ĞµĞ½Ğ½Ñ‹Ğ¼ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ¾Ğ¼

---

### ĞÑˆĞ¸Ğ±ĞºĞ° 4: Timeout

**ĞšĞ¾Ğ³Ğ´Ğ°:** ĞĞ¿ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€ĞµĞ²Ñ‹ÑˆĞ°ĞµÑ‚ Ñ‚Ğ°Ğ¹Ğ¼Ğ°ÑƒÑ‚ (30 ÑĞµĞºÑƒĞ½Ğ´)

**Ğ”ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ:**
- Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ partial Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ
- Ğ˜Ğ»Ğ¸ error message

---

## Ğ¡Ğ²ÑĞ·Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹

### Core Files:
1. [bot_service/advanced_bot.py:1268](bot_service/advanced_bot.py#L1268) - Telegram handler
2. [services/phase3_handlers.py:28](services/phase3_handlers.py#L28) - Phase3 handler
3. [core/context/phase3_context_builder.py:40](core/context/phase3_context_builder.py#L40) - Context builder
4. [core/rag/retrieval_client.py:76](core/rag/retrieval_client.py#L76) - Retrieval client
5. [ranking_api.py:367](ranking_api.py#L367) - Ranking API
6. [database/production_db_client.py:622](database/production_db_client.py#L622) - Database client
7. [core/orchestrator/phase3_orchestrator_new.py:70](core/orchestrator/phase3_orchestrator_new.py#L70) - Orchestrator
8. [core/agents/agentic_rag.py](core/agents/agentic_rag.py) - Agentic RAG agent
9. [core/ux/formatter.py](core/ux/formatter.py) - Formatter

### Supporting Files:
10. [ranking_service/deduplication.py](ranking_service/deduplication.py) - LSH deduplication
11. [core/models/model_router.py](core/models/model_router.py) - Model routing
12. [core/models/budget_manager.py](core/models/budget_manager.py) - Budget management

---

**ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½ĞµĞµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ:** 2025-10-05
**ĞĞ²Ñ‚Ğ¾Ñ€:** Claude Code Agent
**Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ:** âœ… Production Ready
