#!/usr/bin/env python3
"""
üß™ Individual Command Testing Suite
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥–æ–π –∫–æ–º–∞–Ω–¥—ã –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
"""

import asyncio
import json
import logging
import os
import sys
import time
from datetime import datetime
from typing import Dict, Any, List

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('individual_commands_test.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# Load environment
try:
    from dotenv import load_dotenv
    load_dotenv()
    logger.info("‚úÖ Environment loaded")
except ImportError:
    logger.warning("‚ö†Ô∏è dotenv not available")

class IndividualCommandTester:
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º–∞–Ω–¥ –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏"""

    def __init__(self):
        self.results = {}
        self.test_data = self._get_test_data()

    def _get_test_data(self) -> List[Dict[str, Any]]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        return [
            {
                'title': '–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç: –ø—Ä–æ—Ä—ã–≤ –≤ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö 2025',
                'content': '–ù–æ–≤–µ–π—à–∏–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –≤ –æ–±–ª–∞—Å—Ç–∏ –ò–ò –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å. GPT-5 –∏ –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —É–ª—É—á—à–µ–Ω–∏–µ –Ω–∞ 40% –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö. –≠–∫—Å–ø–µ—Ä—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É—é—Ç —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –±–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –∏ –ø—Ä–∏–Ω—è—Ç–∏–∏ —Ä–µ—à–µ–Ω–∏–π.',
                'source': 'TechNews',
                'source_domain': 'technews.com',
                'published_at': '2025-09-25T10:00:00',
                'score': 0.95,
                'tags': ['AI', 'technology', 'automation']
            },
            {
                'title': '–†—ã–Ω–æ–∫ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç: –∞–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ –∏ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤',
                'content': '–ö—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω—ã–π —Ä—ã–Ω–æ–∫ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—é –ø–æ—Å–ª–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞. Bitcoin —Ç–æ—Ä–≥—É–µ—Ç—Å—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ $45,000-$50,000, –ø–æ–∫–∞–∑—ã–≤–∞—è –ø—Ä–∏–∑–Ω–∞–∫–∏ –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏. –ò–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∏–Ω–≤–µ—Å—Ç–æ—Ä—ã –ø—Ä–æ—è–≤–ª—è—é—Ç –≤–æ–∑—Ä–∞—Å—Ç–∞—é—â–∏–π –∏–Ω—Ç–µ—Ä–µ—Å –∫ —Ü–∏—Ñ—Ä–æ–≤—ã–º –∞–∫—Ç–∏–≤–∞–º.',
                'source': 'CryptoDaily',
                'source_domain': 'crypto.daily',
                'published_at': '2025-09-25T09:30:00',
                'score': 0.88,
                'tags': ['crypto', 'market', 'investment']
            },
            {
                'title': '–ó–µ–ª–µ–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –ø—Ä–∏–≤–ª–µ–∫–∞—é—Ç —Ä–µ–∫–æ—Ä–¥–Ω—ã–µ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏',
                'content': '–°–µ–∫—Ç–æ—Ä —ç–∫–æ–ª–æ–≥–∏—á–µ—Å–∫–∏ —á–∏—Å—Ç—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –ø–æ–ª—É—á–∏–ª $127 –º–ª—Ä–¥ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π –≤ 2025 –≥–æ–¥—É. –°–æ–ª–Ω–µ—á–Ω–∞—è —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞ –∏ –≤–µ—Ç—Ä–æ—ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Ä–µ–∫–æ—Ä–¥–Ω—É—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å. –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –∞–∫—Ç–∏–≤–Ω–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç –ø–µ—Ä–µ—Ö–æ–¥ –∫ —É—Å—Ç–æ–π—á–∏–≤–æ–π —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–µ.',
                'source': 'GreenTech',
                'source_domain': 'greentech.org',
                'published_at': '2025-09-25T08:45:00',
                'score': 0.91,
                'tags': ['green', 'energy', 'investment']
            }
        ]

    async def test_analyze_command(self):
        """–¢–µ—Å—Ç –∫–æ–º–∞–Ω–¥—ã /analyze"""
        logger.info("üß† TESTING /analyze COMMAND")
        logger.info("=" * 50)

        try:
            from data_analysis_processor import analyze_data

            # –¢–µ—Å—Ç —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            test_cases = [
                {
                    'name': 'Basic Analysis',
                    'query': '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏',
                    'timeframe': '7d'
                },
                {
                    'name': 'Market Analysis',
                    'query': '—Ä—ã–Ω–æ–∫ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç',
                    'timeframe': '14d'
                },
                {
                    'name': 'Long-term Analysis',
                    'query': '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏',
                    'timeframe': '30d'
                }
            ]

            results = []
            for case in test_cases:
                logger.info(f"\nüî¨ Testing: {case['name']}")

                start_time = time.time()
                result = await analyze_data(
                    query=case['query'],
                    timeframe=case['timeframe']
                )
                processing_time = time.time() - start_time

                # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                analysis_result = self._analyze_result(result, case, processing_time)
                results.append(analysis_result)

                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                self._log_result(case['name'], result, analysis_result)

            self.results['analyze'] = {
                'overall_success': all(r['success'] for r in results),
                'test_cases': results,
                'recommendations': self._generate_analyze_recommendations(results)
            }

        except Exception as e:
            logger.error(f"‚ùå /analyze test failed: {e}")
            self.results['analyze'] = {'error': str(e), 'success': False}

    async def test_summarize_command(self):
        """–¢–µ—Å—Ç –∫–æ–º–∞–Ω–¥—ã /summarize"""
        logger.info("üìã TESTING /summarize COMMAND")
        logger.info("=" * 50)

        try:
            from data_analysis_processor import summarize_data

            test_cases = [
                {
                    'name': 'Short Summary',
                    'topic': '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –Ω–æ–≤–æ—Å—Ç–∏',
                    'length': 'short',
                    'timeframe': '7d'
                },
                {
                    'name': 'Medium Summary',
                    'topic': '—Ä—ã–Ω–æ—á–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞',
                    'length': 'medium',
                    'timeframe': '7d'
                },
                {
                    'name': 'Long Summary',
                    'topic': '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã',
                    'length': 'long',
                    'timeframe': '7d'
                }
            ]

            results = []
            for case in test_cases:
                logger.info(f"\nüìù Testing: {case['name']}")

                start_time = time.time()
                result = await summarize_data(
                    topic=case['topic'],
                    length=case['length'],
                    timeframe=case['timeframe']
                )
                processing_time = time.time() - start_time

                analysis_result = self._analyze_summarize_result(result, case, processing_time)
                results.append(analysis_result)
                self._log_result(case['name'], result, analysis_result)

            self.results['summarize'] = {
                'overall_success': all(r['success'] for r in results),
                'test_cases': results,
                'recommendations': self._generate_summarize_recommendations(results)
            }

        except Exception as e:
            logger.error(f"‚ùå /summarize test failed: {e}")
            self.results['summarize'] = {'error': str(e), 'success': False}

    async def test_aggregate_command(self):
        """–¢–µ—Å—Ç –∫–æ–º–∞–Ω–¥—ã /aggregate"""
        logger.info("üìä TESTING /aggregate COMMAND")
        logger.info("=" * 50)

        try:
            from data_analysis_processor import aggregate_data

            test_cases = [
                {
                    'name': 'Source Aggregation',
                    'metric': '–∏—Å—Ç–æ—á–Ω–∏–∫–∏',
                    'groupby': '–¥–∞—Ç–∞',
                    'query': '–Ω–æ–≤–æ—Å—Ç–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π'
                },
                {
                    'name': 'Content Aggregation',
                    'metric': '–∫–æ–Ω—Ç–µ–Ω—Ç',
                    'groupby': '–∏—Å—Ç–æ—á–Ω–∏–∫',
                    'query': '—Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ'
                },
                {
                    'name': 'Time Aggregation',
                    'metric': '—Ç–µ–º—ã',
                    'groupby': '–≤—Ä–µ–º—è',
                    'query': '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏'
                }
            ]

            results = []
            for case in test_cases:
                logger.info(f"\nüìà Testing: {case['name']}")

                start_time = time.time()
                result = await aggregate_data(
                    metric=case['metric'],
                    groupby=case['groupby'],
                    query=case['query'],
                    timeframe='7d'
                )
                processing_time = time.time() - start_time

                analysis_result = self._analyze_aggregate_result(result, case, processing_time)
                results.append(analysis_result)
                self._log_result(case['name'], result, analysis_result)

            self.results['aggregate'] = {
                'overall_success': all(r['success'] for r in results),
                'test_cases': results,
                'recommendations': self._generate_aggregate_recommendations(results)
            }

        except Exception as e:
            logger.error(f"‚ùå /aggregate test failed: {e}")
            self.results['aggregate'] = {'error': str(e), 'success': False}

    async def test_filter_command(self):
        """–¢–µ—Å—Ç –∫–æ–º–∞–Ω–¥—ã /filter"""
        logger.info("üîç TESTING /filter COMMAND")
        logger.info("=" * 50)

        try:
            from data_analysis_processor import filter_data

            test_cases = [
                {
                    'name': 'Source Filter',
                    'criteria': '–∏—Å—Ç–æ—á–Ω–∏–∫',
                    'value': 'technews.com',
                    'query': '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏'
                },
                {
                    'name': 'Content Filter',
                    'criteria': '—Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ',
                    'value': '–ò–ò',
                    'query': '–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç'
                },
                {
                    'name': 'Title Filter',
                    'criteria': '–Ω–∞–∑–≤–∞–Ω–∏–µ',
                    'value': '—Ä—ã–Ω–æ–∫',
                    'query': '—Ä—ã–Ω–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑'
                }
            ]

            results = []
            for case in test_cases:
                logger.info(f"\nüîé Testing: {case['name']}")

                start_time = time.time()
                result = await filter_data(
                    criteria=case['criteria'],
                    value=case['value'],
                    query=case['query'],
                    timeframe='7d'
                )
                processing_time = time.time() - start_time

                analysis_result = self._analyze_filter_result(result, case, processing_time)
                results.append(analysis_result)
                self._log_result(case['name'], result, analysis_result)

            self.results['filter'] = {
                'overall_success': all(r['success'] for r in results),
                'test_cases': results,
                'recommendations': self._generate_filter_recommendations(results)
            }

        except Exception as e:
            logger.error(f"‚ùå /filter test failed: {e}")
            self.results['filter'] = {'error': str(e), 'success': False}

    async def test_insights_command(self):
        """–¢–µ—Å—Ç –∫–æ–º–∞–Ω–¥—ã /insights"""
        logger.info("üí° TESTING /insights COMMAND")
        logger.info("=" * 50)

        try:
            from data_analysis_processor import generate_insights

            test_cases = [
                {
                    'name': 'Tech Insights',
                    'topic': '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Ä—ã–Ω–æ–∫',
                    'timeframe': '7d'
                },
                {
                    'name': 'Investment Insights',
                    'topic': '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏',
                    'timeframe': '14d'
                },
                {
                    'name': 'Market Insights',
                    'topic': '—Ä—ã–Ω–æ—á–Ω—ã–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏',
                    'timeframe': '30d'
                }
            ]

            results = []
            for case in test_cases:
                logger.info(f"\nüíº Testing: {case['name']}")

                start_time = time.time()
                result = await generate_insights(
                    topic=case['topic'],
                    timeframe=case['timeframe']
                )
                processing_time = time.time() - start_time

                analysis_result = self._analyze_insights_result(result, case, processing_time)
                results.append(analysis_result)
                self._log_result(case['name'], result, analysis_result)

            self.results['insights'] = {
                'overall_success': all(r['success'] for r in results),
                'test_cases': results,
                'recommendations': self._generate_insights_recommendations(results)
            }

        except Exception as e:
            logger.error(f"‚ùå /insights test failed: {e}")
            self.results['insights'] = {'error': str(e), 'success': False}

    async def test_sentiment_command(self):
        """–¢–µ—Å—Ç –∫–æ–º–∞–Ω–¥—ã /sentiment"""
        logger.info("üòä TESTING /sentiment COMMAND")
        logger.info("=" * 50)

        try:
            from data_analysis_processor import analyze_sentiment

            test_cases = [
                {
                    'name': 'Tech Sentiment',
                    'query': '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –Ω–æ–≤–æ—Å—Ç–∏',
                    'timeframe': '7d'
                },
                {
                    'name': 'Market Sentiment',
                    'query': '—Ä—ã–Ω–æ—á–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è',
                    'timeframe': '14d'
                },
                {
                    'name': 'Crypto Sentiment',
                    'query': '–∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω—ã–π —Ä—ã–Ω–æ–∫',
                    'timeframe': '30d'
                }
            ]

            results = []
            for case in test_cases:
                logger.info(f"\nüòä Testing: {case['name']}")

                start_time = time.time()
                result = await analyze_sentiment(
                    query=case['query'],
                    timeframe=case['timeframe']
                )
                processing_time = time.time() - start_time

                analysis_result = self._analyze_sentiment_result(result, case, processing_time)
                results.append(analysis_result)
                self._log_result(case['name'], result, analysis_result)

            self.results['sentiment'] = {
                'overall_success': all(r['success'] for r in results),
                'test_cases': results,
                'recommendations': self._generate_sentiment_recommendations(results)
            }

        except Exception as e:
            logger.error(f"‚ùå /sentiment test failed: {e}")
            self.results['sentiment'] = {'error': str(e), 'success': False}

    async def test_topics_command(self):
        """–¢–µ—Å—Ç –∫–æ–º–∞–Ω–¥—ã /topics"""
        logger.info("üè∑Ô∏è TESTING /topics COMMAND")
        logger.info("=" * 50)

        try:
            from data_analysis_processor import analyze_topics

            test_cases = [
                {
                    'name': 'Tech Topics',
                    'scope': '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–Ω–¥—ã',
                    'timeframe': '7d'
                },
                {
                    'name': 'Market Topics',
                    'scope': '—Ä—ã–Ω–æ—á–Ω–∞—è –¥–∏–Ω–∞–º–∏–∫–∞',
                    'timeframe': '14d'
                },
                {
                    'name': 'Innovation Topics',
                    'scope': '–∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è',
                    'timeframe': '30d'
                }
            ]

            results = []
            for case in test_cases:
                logger.info(f"\nüè∑Ô∏è Testing: {case['name']}")

                start_time = time.time()
                result = await analyze_topics(
                    scope=case['scope'],
                    timeframe=case['timeframe']
                )
                processing_time = time.time() - start_time

                analysis_result = self._analyze_topics_result(result, case, processing_time)
                results.append(analysis_result)
                self._log_result(case['name'], result, analysis_result)

            self.results['topics'] = {
                'overall_success': all(r['success'] for r in results),
                'test_cases': results,
                'recommendations': self._generate_topics_recommendations(results)
            }

        except Exception as e:
            logger.error(f"‚ùå /topics test failed: {e}")
            self.results['topics'] = {'error': str(e), 'success': False}

    def _analyze_result(self, result, case, processing_time):
        """–ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        analysis = {
            'success': result.success,
            'processing_time': processing_time,
            'case_name': case['name'],
            'metadata': result.metadata if result.success else None,
            'issues': [],
            'strengths': []
        }

        if result.success:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            if 'analysis' in result.data:
                content = result.data['analysis']
                if len(content) < 50:
                    analysis['issues'].append('–ê–Ω–∞–ª–∏–∑ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π')
                elif len(content) > 100:
                    analysis['strengths'].append('–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑')

            if processing_time < 1.0:
                analysis['strengths'].append('–ë—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞')
            elif processing_time > 5.0:
                analysis['issues'].append('–ú–µ–¥–ª–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞')

        else:
            analysis['issues'].append(f'–û—à–∏–±–∫–∞: {result.error}')

        return analysis

    def _analyze_summarize_result(self, result, case, processing_time):
        """–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏"""
        analysis = self._analyze_result(result, case, processing_time)

        if result.success and 'summary' in result.data:
            word_count = result.data.get('word_count', 0)
            expected_ranges = {
                'short': (20, 100),
                'medium': (50, 200),
                'long': (100, 400)
            }

            expected_range = expected_ranges.get(case['length'], (50, 200))
            if expected_range[0] <= word_count <= expected_range[1]:
                analysis['strengths'].append(f'–ö–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –¥–ª–∏–Ω–∞: {word_count} —Å–ª–æ–≤')
            else:
                analysis['issues'].append(f'–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –¥–ª–∏–Ω–∞: {word_count} (–æ–∂–∏–¥–∞–ª–æ—Å—å {expected_range})')

        return analysis

    def _analyze_aggregate_result(self, result, case, processing_time):
        """–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏"""
        analysis = self._analyze_result(result, case, processing_time)

        if result.success:
            if 'raw_aggregation' in result.data:
                analysis['strengths'].append('–ï—Å—Ç—å —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏')

            if 'aggregation_analysis' in result.data:
                analysis['strengths'].append('–ï—Å—Ç—å –∞–Ω–∞–ª–∏–∑ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏')

        return analysis

    def _analyze_filter_result(self, result, case, processing_time):
        """–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏"""
        analysis = self._analyze_result(result, case, processing_time)

        if result.success and 'filter_stats' in result.data:
            stats = result.data['filter_stats']
            filter_ratio = stats.get('filter_ratio', 0)

            if 0 < filter_ratio < 1:
                analysis['strengths'].append(f'–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è: {filter_ratio:.1%}')
            elif filter_ratio == 0:
                analysis['issues'].append('–§–∏–ª—å—Ç—Ä –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–µ–ª')
            elif filter_ratio == 1:
                analysis['issues'].append('–§–∏–ª—å—Ç—Ä –Ω–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–ª –Ω–∏—á–µ–≥–æ')

        return analysis

    def _analyze_insights_result(self, result, case, processing_time):
        """–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏–Ω—Å–∞–π—Ç–æ–≤"""
        analysis = self._analyze_result(result, case, processing_time)

        if result.success:
            confidence = result.data.get('confidence_score', 0)
            if confidence > 0.7:
                analysis['strengths'].append(f'–í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f}')
            elif confidence < 0.3:
                analysis['issues'].append(f'–ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f}')

        return analysis

    def _analyze_sentiment_result(self, result, case, processing_time):
        """–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏"""
        analysis = self._analyze_result(result, case, processing_time)

        if result.success and 'sentiment_metrics' in result.data:
            metrics = result.data['sentiment_metrics']
            avg_sentiment = metrics.get('average_sentiment', 0)

            if -1 <= avg_sentiment <= 1:
                analysis['strengths'].append(f'–ö–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {avg_sentiment:.2f}')
            else:
                analysis['issues'].append(f'–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {avg_sentiment}')

        return analysis

    def _analyze_topics_result(self, result, case, processing_time):
        """–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ–º"""
        analysis = self._analyze_result(result, case, processing_time)

        if result.success and 'topic_metrics' in result.data:
            metrics = result.data['topic_metrics']
            diversity = metrics.get('topic_diversity', 0)

            if diversity > 0.1:
                analysis['strengths'].append(f'–•–æ—Ä–æ—à–µ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ —Ç–µ–º: {diversity:.2f}')
            else:
                analysis['issues'].append(f'–ù–∏–∑–∫–æ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ —Ç–µ–º: {diversity:.2f}')

        return analysis

    def _log_result(self, test_name, result, analysis):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Ç–µ—Å—Ç–∞"""
        status = "‚úÖ SUCCESS" if analysis['success'] else "‚ùå FAILED"
        logger.info(f"   {status} - {test_name}")
        logger.info(f"     ‚è±Ô∏è Time: {analysis['processing_time']:.2f}s")

        if analysis['strengths']:
            logger.info(f"     üí™ Strengths: {', '.join(analysis['strengths'])}")

        if analysis['issues']:
            logger.info(f"     ‚ö†Ô∏è Issues: {', '.join(analysis['issues'])}")

        if result.success and result.data:
            for key, value in result.data.items():
                if isinstance(value, str) and len(value) > 100:
                    logger.info(f"     üìÑ {key}: {value[:100]}...")
                elif not isinstance(value, dict):
                    logger.info(f"     üìä {key}: {value}")

    def _generate_analyze_recommendations(self, results):
        """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –∫–æ–º–∞–Ω–¥—ã analyze"""
        recommendations = []

        # –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        avg_time = sum(r['processing_time'] for r in results) / len(results)
        if avg_time > 3.0:
            recommendations.append("–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞–Ω–∞–ª–∏–∑–∞")

        # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        short_analyses = sum(1 for r in results if '–ê–Ω–∞–ª–∏–∑ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π' in r.get('issues', []))
        if short_analyses > 0:
            recommendations.append("–£–≤–µ–ª–∏—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞")

        return recommendations

    def _generate_summarize_recommendations(self, results):
        """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –∫–æ–º–∞–Ω–¥—ã summarize"""
        recommendations = []

        length_issues = sum(1 for r in results if any('–¥–ª–∏–Ω–∞' in issue for issue in r.get('issues', [])))
        if length_issues > 0:
            recommendations.append("–ù–∞—Å—Ç—Ä–æ–∏—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–ª–∏–Ω—ã —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏")

        return recommendations

    def _generate_aggregate_recommendations(self, results):
        """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –∫–æ–º–∞–Ω–¥—ã aggregate"""
        recommendations = []

        missing_data = sum(1 for r in results if not r.get('success'))
        if missing_data > 0:
            recommendations.append("–£–ª—É—á—à–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö –∞–≥—Ä–µ–≥–∞—Ü–∏–∏")

        return recommendations

    def _generate_filter_recommendations(self, results):
        """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –∫–æ–º–∞–Ω–¥—ã filter"""
        recommendations = []

        ineffective_filters = sum(1 for r in results if '–Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–µ–ª' in str(r.get('issues', [])))
        if ineffective_filters > 0:
            recommendations.append("–£–ª—É—á—à–∏—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")

        return recommendations

    def _generate_insights_recommendations(self, results):
        """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –∫–æ–º–∞–Ω–¥—ã insights"""
        recommendations = []

        low_confidence = sum(1 for r in results if '–ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å' in str(r.get('issues', [])))
        if low_confidence > 0:
            recommendations.append("–ü–æ–≤—ã—Å–∏—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–Ω—Å–∞–π—Ç–æ–≤")

        return recommendations

    def _generate_sentiment_recommendations(self, results):
        """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –∫–æ–º–∞–Ω–¥—ã sentiment"""
        recommendations = []

        incorrect_sentiment = sum(1 for r in results if '–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å' in str(r.get('issues', [])))
        if incorrect_sentiment > 0:
            recommendations.append("–ò—Å–ø—Ä–∞–≤–∏—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏")

        return recommendations

    def _generate_topics_recommendations(self, results):
        """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –∫–æ–º–∞–Ω–¥—ã topics"""
        recommendations = []

        low_diversity = sum(1 for r in results if '–ù–∏–∑–∫–æ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ' in str(r.get('issues', [])))
        if low_diversity > 0:
            recommendations.append("–£–ª—É—á—à–∏—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º –≤—ã—è–≤–ª–µ–Ω–∏—è —Ç–µ–º")

        return recommendations

    async def run_all_individual_tests(self):
        """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤"""
        logger.info("üöÄ Starting Individual Command Testing")
        logger.info(f"‚è∞ Start time: {datetime.now()}")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ API –∫–ª—é—á–∞
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            logger.error("‚ùå OPENAI_API_KEY not found!")
            return

        # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ –ø–æ –æ—á–µ—Ä–µ–¥–∏
        await self.test_analyze_command()
        await self.test_summarize_command()
        await self.test_aggregate_command()
        await self.test_filter_command()
        await self.test_insights_command()
        await self.test_sentiment_command()
        await self.test_topics_command()

        # –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        self.generate_final_report()

    def generate_final_report(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        logger.info("\n" + "=" * 80)
        logger.info("üìã FINAL INDIVIDUAL TESTING REPORT")
        logger.info("=" * 80)

        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_commands = len(self.results)
        successful_commands = sum(1 for r in self.results.values() if r.get('overall_success', False))

        logger.info(f"üìä OVERALL STATISTICS:")
        logger.info(f"   ‚úÖ Successful commands: {successful_commands}/{total_commands}")
        logger.info(f"   ‚ùå Failed commands: {total_commands - successful_commands}/{total_commands}")

        # –î–µ—Ç–∞–ª–∏ –ø–æ –∫–∞–∂–¥–æ–π –∫–æ–º–∞–Ω–¥–µ
        logger.info(f"\nüìã COMMAND DETAILS:")
        for cmd_name, cmd_results in self.results.items():
            if 'error' in cmd_results:
                logger.info(f"   ‚ùå /{cmd_name}: ERROR - {cmd_results['error']}")
            else:
                success_rate = cmd_results.get('overall_success', False)
                status = "‚úÖ" if success_rate else "‚ö†Ô∏è"

                test_cases = cmd_results.get('test_cases', [])
                passed_cases = sum(1 for tc in test_cases if tc['success'])
                total_cases = len(test_cases)

                logger.info(f"   {status} /{cmd_name}: {passed_cases}/{total_cases} test cases passed")

                # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                recommendations = cmd_results.get('recommendations', [])
                if recommendations:
                    logger.info(f"      üí° Recommendations:")
                    for rec in recommendations:
                        logger.info(f"         - {rec}")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
        report_data = {
            'timestamp': datetime.now().isoformat(),
            'summary': {
                'total_commands': total_commands,
                'successful_commands': successful_commands,
                'success_rate': successful_commands / total_commands * 100 if total_commands > 0 else 0
            },
            'detailed_results': self.results
        }

        try:
            with open('individual_commands_report.json', 'w', encoding='utf-8') as f:
                json.dump(report_data, f, ensure_ascii=False, indent=2)
            logger.info(f"\nüìÑ Detailed report saved to: individual_commands_report.json")
        except Exception as e:
            logger.error(f"‚ùå Failed to save report: {e}")

        logger.info("=" * 80)


async def test_single_command(command_name: str):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∫–æ–º–∞–Ω–¥—ã"""
    tester = IndividualCommandTester()

    if command_name == 'analyze':
        await tester.test_analyze_command()
    elif command_name == 'summarize':
        await tester.test_summarize_command()
    elif command_name == 'aggregate':
        await tester.test_aggregate_command()
    elif command_name == 'filter':
        await tester.test_filter_command()
    elif command_name == 'insights':
        await tester.test_insights_command()
    elif command_name == 'sentiment':
        await tester.test_sentiment_command()
    elif command_name == 'topics':
        await tester.test_topics_command()
    else:
        logger.error(f"‚ùå Unknown command: {command_name}")
        return

    # –ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –æ–¥–Ω–æ–π –∫–æ–º–∞–Ω–¥—ã
    if command_name in tester.results:
        result = tester.results[command_name]
        logger.info(f"\nüéØ RESULTS FOR /{command_name}:")
        logger.info(f"   Success: {result.get('overall_success', False)}")

        if 'recommendations' in result:
            logger.info(f"   Recommendations: {result['recommendations']}")


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    if len(sys.argv) > 1:
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–π –∫–æ–º–∞–Ω–¥—ã
        command = sys.argv[1]
        await test_single_command(command)
    else:
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –∫–æ–º–∞–Ω–¥
        tester = IndividualCommandTester()
        await tester.run_all_individual_tests()


if __name__ == "__main__":
    asyncio.run(main())