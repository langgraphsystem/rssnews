#!/usr/bin/env python3
"""
–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è /analyze –∫–æ–º–∞–Ω–¥—ã
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–∞–±–ª–∏—Ü—É article_chunks –∏ —Å—Ç–æ–ª–±–µ—Ü embedding_vector
"""
import os
import psycopg2
from dotenv import load_dotenv

load_dotenv()

def main():
    print("=" * 80)
    print("–ü–†–û–í–ï–†–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø /ANALYZE")
    print("=" * 80)

    # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
    pg_dsn = os.getenv("PG_DSN")
    if not pg_dsn:
        # –ü–æ–ø—Ä–æ–±—É–µ–º Railway –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
        db_url = os.getenv("DATABASE_URL")
        if db_url:
            pg_dsn = db_url
        else:
            print("‚ùå PG_DSN –∏–ª–∏ DATABASE_URL –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
            print("\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ:")
            print("  railway run python check_analyze_columns.py")
            return

    try:
        conn = psycopg2.connect(pg_dsn)
        cur = conn.cursor()

        db_name = pg_dsn.split('/')[-1].split('?')[0] if '/' in pg_dsn else 'unknown'
        print(f"\nüìä –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {db_name}")

        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –∏ —Å—Ç–æ–ª–±—Ü–æ–≤
        print("\n" + "=" * 80)
        print("1. –°–¢–†–£–ö–¢–£–†–ê –¢–ê–ë–õ–ò–¶–´ article_chunks")
        print("=" * 80)

        cur.execute("""
            SELECT column_name, data_type, is_nullable
            FROM information_schema.columns
            WHERE table_name = 'article_chunks'
            AND column_name IN ('embedding', 'embedding_vector', 'text', 'published_at')
            ORDER BY ordinal_position
        """)

        columns = cur.fetchall()
        if columns:
            print("\nüìã –°—Ç–æ–ª–±—Ü—ã:")
            for col in columns:
                print(f"  - {col[0]:<25} | –¢–∏–ø: {col[1]:<20} | NULL: {col[2]}")
        else:
            print("‚ùå –¢–∞–±–ª–∏—Ü–∞ article_chunks –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∏–ª–∏ –Ω–µ –∏–º–µ–µ—Ç –Ω—É–∂–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤")
            return

        # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω–¥–µ–∫—Å—ã
        print("\n" + "=" * 80)
        print("2. –ò–ù–î–ï–ö–°–´")
        print("=" * 80)

        cur.execute("""
            SELECT indexname, indexdef
            FROM pg_indexes
            WHERE tablename = 'article_chunks'
            AND (indexdef ILIKE '%embedding_vector%' OR indexdef ILIKE '%hnsw%' OR indexdef ILIKE '%ivfflat%')
            ORDER BY indexname
        """)

        indexes = cur.fetchall()
        if indexes:
            print("\nüîç –ù–∞–π–¥–µ–Ω–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã:")
            for idx in indexes:
                print(f"\n  üìå {idx[0]}")
                print(f"     {idx[1][:150]}")
        else:
            print("‚ö†Ô∏è  –í–µ–∫—Ç–æ—Ä–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã (–º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ–¥–ª–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫)")

        # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
        print("\n" + "=" * 80)
        print("3. –î–ê–ù–ù–´–ï –ó–ê –ü–û–°–õ–ï–î–ù–ò–ï 24 –ß–ê–°–ê")
        print("=" * 80)

        # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
        cur.execute("""
            SELECT COUNT(*)
            FROM article_chunks
            WHERE published_at >= NOW() - INTERVAL '24 hours'
        """)
        total_24h = cur.fetchone()[0]

        # –° embedding_vector
        cur.execute("""
            SELECT COUNT(*)
            FROM article_chunks
            WHERE published_at >= NOW() - INTERVAL '24 hours'
            AND embedding_vector IS NOT NULL
        """)
        with_embedding = cur.fetchone()[0]

        # –° embedding (—Ç–µ–∫—Å—Ç–æ–≤—ã–π)
        cur.execute("""
            SELECT COUNT(*)
            FROM article_chunks
            WHERE published_at >= NOW() - INTERVAL '24 hours'
            AND embedding IS NOT NULL
        """)
        with_text_embedding = cur.fetchone()[0]

        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"  –í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤ (24—á):          {total_24h}")
        print(f"  –° embedding_vector:          {with_embedding} ({with_embedding/total_24h*100 if total_24h else 0:.1f}%)")
        print(f"  –° embedding (—Ç–µ–∫—Å—Ç):         {with_text_embedding} ({with_text_embedding/total_24h*100 if total_24h else 0:.1f}%)")

        # –û—Ü–µ–Ω–∫–∞
        if with_embedding == 0:
            print("\n‚ùå –ü–†–û–ë–õ–ï–ú–ê: embedding_vector –ø—É—Å—Ç–æ–π!")
            print("   /analyze –ù–ï –ë–£–î–ï–¢ –†–ê–ë–û–¢–ê–¢–¨")
            print("\n   –í–æ–∑–º–æ–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è:")
            print("   1. –ó–∞–ø—É—Å—Ç–∏—Ç—å –º–∏–≥—Ä–∞—Ü–∏—é embeddings")
            print("   2. –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–µ—Ä–≤–∏—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ embeddings")
        elif with_embedding < total_24h * 0.5:
            print(f"\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –¢–æ–ª—å–∫–æ {with_embedding/total_24h*100:.1f}% —á–∞–Ω–∫–æ–≤ –∏–º–µ—é—Ç embeddings")
            print("   /analyze –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏")
        else:
            print(f"\n‚úÖ –•–û–†–û–®–û: {with_embedding/total_24h*100:.1f}% —á–∞–Ω–∫–æ–≤ –∏–º–µ—é—Ç embeddings")

        # 4. –ü—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö
        if with_embedding > 0:
            print("\n" + "=" * 80)
            print("4. –ü–†–ò–ú–ï–†–´ –ß–ê–ù–ö–û–í –° EMBEDDINGS")
            print("=" * 80)

            cur.execute("""
                SELECT
                    article_id,
                    chunk_index,
                    title_norm,
                    LEFT(text, 100) as text_preview,
                    published_at,
                    CASE WHEN embedding_vector IS NOT NULL THEN 'YES' ELSE 'NO' END as has_vector
                FROM article_chunks
                WHERE published_at >= NOW() - INTERVAL '24 hours'
                AND embedding_vector IS NOT NULL
                ORDER BY published_at DESC
                LIMIT 5
            """)

            examples = cur.fetchall()
            print(f"\nüîç –ü–æ—Å–ª–µ–¥–Ω–∏–µ {len(examples)} —á–∞–Ω–∫–æ–≤ —Å embeddings:")
            for ex in examples:
                pub_time = ex[4].strftime('%Y-%m-%d %H:%M') if ex[4] else 'unknown'
                print(f"\n  ‚Ä¢ [{pub_time}] {ex[2]}")
                print(f"    –ß–∞–Ω–∫ {ex[1]}: {ex[3]}...")
                print(f"    Vector: {ex[5]}")

        # 5. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å embeddings
        print("\n" + "=" * 80)
        print("5. –†–ê–ó–ú–ï–†–ù–û–°–¢–¨ EMBEDDINGS")
        print("=" * 80)

        if with_embedding > 0:
            # –î–ª—è pgvector –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é vector_dims
            try:
                cur.execute("""
                    SELECT
                        vector_dims(embedding_vector) as dimension,
                        COUNT(*) as count
                    FROM article_chunks
                    WHERE embedding_vector IS NOT NULL
                    AND published_at >= NOW() - INTERVAL '24 hours'
                    GROUP BY dimension
                    ORDER BY count DESC
                """)

                dimensions = cur.fetchall()
                print("\nüìè –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏:")
                for dim in dimensions:
                    if dim[0]:
                        print(f"  - {dim[0]} –∏–∑–º–µ—Ä–µ–Ω–∏–π: {dim[1]} —á–∞–Ω–∫–æ–≤")
                        if dim[0] == 1536:
                            print("    ‚úÖ OpenAI text-embedding-ada-002 (1536)")
                        elif dim[0] == 3072:
                            print("    ‚úÖ OpenAI text-embedding-3-large (3072)")
                        elif dim[0] == 768:
                            print("    ‚ö†Ô∏è  BERT-like model (768)")
            except Exception as e:
                print(f"\n‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {e}")
        else:
            print("\n‚ö†Ô∏è  –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏")

        # 6. –ò—Ç–æ–≥–∏
        print("\n" + "=" * 80)
        print("–ò–¢–û–ì–ò")
        print("=" * 80)

        print("\nüìå –ö–æ–º–∞–Ω–¥–∞ /analyze –∏—Å–ø–æ–ª—å–∑—É–µ—Ç:")
        print("   –¢–∞–±–ª–∏—Ü–∞:  article_chunks")
        print("   –°—Ç–æ–ª–±–µ—Ü:  embedding_vector (pgvector)")
        print("   –ü–æ–∏—Å–∫:    –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ (<=> –æ–ø–µ—Ä–∞—Ç–æ—Ä)")
        print("   –ò–Ω–¥–µ–∫—Å:   HNSW –∏–ª–∏ IVFFlat (–µ—Å–ª–∏ –µ—Å—Ç—å)")

        print(f"\nüìä –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ:")
        if with_embedding > 0:
            print(f"   ‚úÖ –î–∞–Ω–Ω—ã–µ –µ—Å—Ç—å: {with_embedding} —á–∞–Ω–∫–æ–≤ —Å embeddings")
            print(f"   ‚úÖ /analyze –¥–æ–ª–∂–Ω–∞ —Ä–∞–±–æ—Ç–∞—Ç—å")
            if with_embedding < total_24h * 0.8:
                print(f"   ‚ö†Ô∏è  –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–∑–∞–ø–æ–ª–Ω–∏—Ç—å embeddings ({with_embedding/total_24h*100:.1f}% –ø–æ–∫—Ä—ã—Ç–∏–µ)")
        else:
            print(f"   ‚ùå –î–∞–Ω–Ω—ã—Ö –Ω–µ—Ç!")
            print(f"   ‚ùå /analyze –ù–ï –†–ê–ë–û–¢–ê–ï–¢")
            print(f"\n   –ù–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–µ–π—Å—Ç–≤–∏—è:")
            print(f"   1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–µ—Ä–≤–∏—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ embeddings")
            print(f"   2. –ó–∞–ø—É—Å—Ç–∏—Ç—å –º–∏–≥—Ä–∞—Ü–∏—é –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å—Ç–∞—Ç–µ–π")

        cur.close()
        conn.close()

    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
