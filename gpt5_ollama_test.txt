2025-09-25 07:58:47,553 - __main__ - INFO - ğŸš€ GPT-5 OLLAMA FALLBACK TESTING SUITE
2025-09-25 07:58:47,554 - __main__ - INFO - ================================================================================
2025-09-25 07:58:47,554 - __main__ - INFO - â° Started at: 2025-09-25 07:58:47.554303
2025-09-25 07:58:47,914 - httpx - INFO - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2025-09-25 07:58:47,914 - __main__ - INFO - âœ… Ollama available with 5 models
2025-09-25 07:58:47,915 - __main__ - INFO -    - all-minilm:l6-v2
2025-09-25 07:58:47,915 - __main__ - INFO -    - embeddinggemma:latest
2025-09-25 07:58:47,915 - __main__ - INFO -    - qwen2.5-coder:3b
2025-09-25 07:58:47,915 - __main__ - INFO -    - qwen2.5-coder:7b
2025-09-25 07:58:47,915 - __main__ - INFO -    - gemma3:latest
2025-09-25 07:58:47,915 - __main__ - INFO - 
ğŸ¯ Running tests with 5 available models
2025-09-25 07:58:47,915 - __main__ - INFO - 
ğŸ§ª TESTING GPT-5 STYLE RESPONSES WITH OLLAMA
2025-09-25 07:58:47,915 - __main__ - INFO - ============================================================
2025-09-25 07:58:47,915 - __main__ - INFO - 
ğŸ“‹ Testing scenario: Market Analysis
2025-09-25 07:58:47,915 - __main__ - INFO -    Max tokens: 1000
2025-09-25 07:58:47,915 - __main__ - INFO -    Expected sections: ['trends', 'market', 'technical', 'future', 'investment']
2025-09-25 07:58:47,915 - __main__ - INFO - ğŸ¤– Using Ollama model: qwen2.5-coder:3b
2025-09-25 07:59:10,821 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-09-25 07:59:10,832 - __main__ - INFO - âœ… Generated 5383 characters
2025-09-25 07:59:10,834 - __main__ - INFO - âœ… Response generated successfully
2025-09-25 07:59:10,834 - __main__ - INFO -    ğŸ“ Length: 5383 characters
2025-09-25 07:59:10,834 - __main__ - INFO -    â±ï¸ Time: 22.92 seconds
2025-09-25 07:59:10,834 - __main__ - INFO -    ğŸ—ï¸ Has structure: True
2025-09-25 07:59:10,834 - __main__ - INFO -    ğŸ˜Š Has emojis: False
2025-09-25 07:59:10,834 - __main__ - INFO -    ğŸ“‘ Sections found: 5/5
2025-09-25 07:59:10,835 - __main__ - INFO - 
ğŸ“‹ Testing scenario: Sentiment Analysis
2025-09-25 07:59:10,835 - __main__ - INFO -    Max tokens: 800
2025-09-25 07:59:10,835 - __main__ - INFO -    Expected sections: ['sentiment', 'factors', 'sector', 'risk', 'opportunities']
2025-09-25 07:59:10,835 - __main__ - INFO - ğŸ¤– Using Ollama model: qwen2.5-coder:3b
2025-09-25 07:59:22,726 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-09-25 07:59:22,727 - __main__ - INFO - âœ… Generated 3625 characters
2025-09-25 07:59:22,728 - __main__ - INFO - âœ… Response generated successfully
2025-09-25 07:59:22,728 - __main__ - INFO -    ğŸ“ Length: 3625 characters
2025-09-25 07:59:22,728 - __main__ - INFO -    â±ï¸ Time: 11.89 seconds
2025-09-25 07:59:22,728 - __main__ - INFO -    ğŸ—ï¸ Has structure: True
2025-09-25 07:59:22,728 - __main__ - INFO -    ğŸ˜Š Has emojis: True
2025-09-25 07:59:22,728 - __main__ - INFO -    ğŸ“‘ Sections found: 5/5
2025-09-25 07:59:22,728 - __main__ - INFO - 
ğŸ“‹ Testing scenario: Topic Modeling
2025-09-25 07:59:22,728 - __main__ - INFO -    Max tokens: 1200
2025-09-25 07:59:22,728 - __main__ - INFO -    Expected sections: ['topics', 'scores', 'themes', 'relationships', 'predictions']
2025-09-25 07:59:22,728 - __main__ - INFO - ğŸ¤– Using Ollama model: qwen2.5-coder:3b
2025-09-25 07:59:38,717 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-09-25 07:59:38,722 - __main__ - INFO - âœ… Generated 4128 characters
2025-09-25 07:59:38,723 - __main__ - INFO - âœ… Response generated successfully
2025-09-25 07:59:38,723 - __main__ - INFO -    ğŸ“ Length: 4128 characters
2025-09-25 07:59:38,723 - __main__ - INFO -    â±ï¸ Time: 15.99 seconds
2025-09-25 07:59:38,723 - __main__ - INFO -    ğŸ—ï¸ Has structure: True
2025-09-25 07:59:38,724 - __main__ - INFO -    ğŸ˜Š Has emojis: False
2025-09-25 07:59:38,724 - __main__ - INFO -    ğŸ“‘ Sections found: 5/5
2025-09-25 07:59:38,724 - __main__ - INFO - 
ğŸ¤– TESTING BOT INTEGRATION SIMULATION
2025-09-25 07:59:38,724 - __main__ - INFO - ============================================================
2025-09-25 07:59:38,724 - __main__ - INFO - 
ğŸ“± Simulating command: /analyze AI trends 3d
2025-09-25 07:59:38,724 - __main__ - INFO - ğŸ¤– Using Ollama model: qwen2.5-coder:3b
2025-09-25 07:59:49,332 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-09-25 07:59:49,332 - __main__ - INFO - âœ… Generated 3205 characters
2025-09-25 07:59:49,333 - __main__ - INFO - âœ… Command simulation successful
2025-09-25 07:59:49,333 - __main__ - INFO -    ğŸ“ Response length: 3205 characters
2025-09-25 07:59:49,333 - __main__ - INFO -    â±ï¸ Generation time: 10.61s
2025-09-25 07:59:49,334 - __main__ - INFO - 
ğŸ“± Simulating command: /insights cryptocurrency market
2025-09-25 07:59:49,334 - __main__ - INFO - ğŸ¤– Using Ollama model: qwen2.5-coder:3b
2025-09-25 07:59:58,023 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-09-25 07:59:58,024 - __main__ - INFO - âœ… Generated 2489 characters
2025-09-25 07:59:58,024 - __main__ - INFO - âœ… Command simulation successful
2025-09-25 07:59:58,024 - __main__ - INFO -    ğŸ“ Response length: 2489 characters
2025-09-25 07:59:58,024 - __main__ - INFO -    â±ï¸ Generation time: 8.69s
2025-09-25 07:59:58,024 - __main__ - INFO - 
ğŸ“± Simulating command: /sentiment tech stocks
2025-09-25 07:59:58,024 - __main__ - INFO - ğŸ¤– Using Ollama model: qwen2.5-coder:3b
2025-09-25 08:00:05,939 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-09-25 08:00:05,940 - __main__ - INFO - âœ… Generated 2342 characters
2025-09-25 08:00:05,940 - __main__ - INFO - âœ… Command simulation successful
2025-09-25 08:00:05,940 - __main__ - INFO -    ğŸ“ Response length: 2342 characters
2025-09-25 08:00:05,940 - __main__ - INFO -    â±ï¸ Generation time: 7.92s
2025-09-25 08:00:05,940 - __main__ - INFO - 
================================================================================
2025-09-25 08:00:05,940 - __main__ - INFO - ğŸ“Š TEST SUMMARY REPORT
2025-09-25 08:00:05,940 - __main__ - INFO - ================================================================================
2025-09-25 08:00:05,940 - __main__ - INFO - ğŸ¤– Ollama Status: âœ… Available
2025-09-25 08:00:05,940 - __main__ - INFO - ğŸ“‹ Models Available: 5
2025-09-25 08:00:05,940 - __main__ - INFO - 
ğŸ“ GPT-5 Style Response Tests:
2025-09-25 08:00:05,940 - __main__ - INFO -    âœ… Successful: 3/3
2025-09-25 08:00:05,940 - __main__ - INFO -    â±ï¸ Average generation time: 16.94s
2025-09-25 08:00:05,940 - __main__ - INFO -    ğŸ“ Average response length: 4379 characters
2025-09-25 08:00:05,940 - __main__ - INFO - 
ğŸ¤– Bot Integration Simulations:
2025-09-25 08:00:05,940 - __main__ - INFO -    âœ… Successful: 3/3
2025-09-25 08:00:05,940 - __main__ - INFO -    â±ï¸ Average generation time: 9.07s
2025-09-25 08:00:05,940 - __main__ - INFO - 
ğŸ¯ Quality Assessment:
2025-09-25 08:00:05,940 - __main__ - INFO -    ğŸ—ï¸ Structured responses: 3/3
2025-09-25 08:00:05,941 - __main__ - INFO -    ğŸ˜Š Responses with emojis: 1/3
2025-09-25 08:00:05,941 - __main__ - INFO - 
ğŸ“ Generated files:
2025-09-25 08:00:05,941 - __main__ - INFO -    - gpt5_ollama_test.txt (test log)
2025-09-25 08:00:05,941 - __main__ - INFO -    - ollama_response_*.txt (detailed responses)
2025-09-25 08:00:05,941 - __main__ - INFO -    - bot_simulation_*.txt (bot integration simulations)
2025-09-25 08:00:05,941 - __main__ - INFO - 
âœ… Testing completed at: 2025-09-25 08:00:05.941862
2025-09-25 08:00:05,941 - __main__ - INFO - 
ğŸ’¡ RECOMMENDATIONS:
2025-09-25 08:00:05,941 - __main__ - INFO -    âœ… Ollama fallback is working and can be used for GPT-5 functionality
2025-09-25 08:00:05,941 - __main__ - INFO -    âœ… Local models can provide structured, emoji-formatted responses
2025-09-25 08:00:05,941 - __main__ - INFO -    âœ… Bot integration is feasible with current setup
2025-09-25 08:00:05,941 - __main__ - INFO -    ğŸ’¡ Consider implementing Ollama fallback in production bot
